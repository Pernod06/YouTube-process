"""
Python + Flask åç«¯ç¤ºä¾‹
å®‰è£…ä¾èµ–: pip install flask flask-cors
"""

from flask import Flask, jsonify, request, send_from_directory, send_file
from flask_cors import CORS
import json
import os
from datetime import date, datetime
from pathlib import Path
from pdf_generator import generate_video_pdf
from video_frame_extractor import extract_frame_at_timestamp

# æ·»åŠ ä»¥ä¸‹ä»£ç æ¥åŠ è½½ .env æ–‡ä»¶
try:
    from dotenv import load_dotenv
    env_path = Path(__file__).parent.parent.parent / '.env'
    load_dotenv(dotenv_path=env_path)
    print(f"[App] .env æ–‡ä»¶å·²åŠ è½½")
except ImportError:
    print("[App] python-dotenv æœªå®‰è£…")

app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# é…ç½®
BASE_DIR = Path(__file__).parent.parent.parent
DATA_DIR = BASE_DIR / 'data'
STATIC_DIR = BASE_DIR

# å†…å­˜å­˜å‚¨ï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨æ•°æ®åº“ï¼‰
comments_db = {}
progress_db = {}


def load_video_data():
    """åŠ è½½è§†é¢‘æ•°æ®"""
    data_path = DATA_DIR / 'video-data.json'
    with open(data_path, 'r', encoding='utf-8') as f:
        return json.load(f)


@app.route('/api/videos/<video_id>', methods=['GET'])
def get_video(video_id):
    """è·å–è§†é¢‘æ•°æ®"""
    try:
        video_data = load_video_data()
        # å¯ä»¥æ ¹æ® video_id è¿‡æ»¤æ•°æ®
        return jsonify(video_data)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/videos', methods=['GET'])
def get_videos():
    """è·å–è§†é¢‘åˆ—è¡¨"""
    videos = [
        {
            'videoId': 'lQHK61IDFH4',
            'title': 'NVIDIA GTC Washington D.C. Keynote',
            'description': 'CEO Jensen Huang keynote',
            'thumbnail': 'https://img.youtube.com/vi/lQHK61IDFH4/maxresdefault.jpg',
            'duration': '01:42:25',
            'uploadDate': '2024-03-18'
        }
    ]
    return jsonify(videos)


@app.route('/api/videos/<video_id>/comments', methods=['GET'])
def get_comments(video_id):
    """è·å–YouTubeè¯„è®º"""
    try:
        # å°è¯•å¯¼å…¥ youtube_client
        import sys
        import traceback
        sys.path.append(str(BASE_DIR))
        
        print(f"[INFO] æ­£åœ¨è·å–è§†é¢‘ {video_id} çš„è¯„è®º...")
        
        from youtube_client import YouTubeClient
        
        # åˆ›å»º YouTube å®¢æˆ·ç«¯
        print("[INFO] æ­£åœ¨åˆå§‹åŒ– YouTube å®¢æˆ·ç«¯...")
        client = YouTubeClient()
        
        # è·å–è¯„è®ºæ•°é‡å‚æ•°ï¼ˆé»˜è®¤20æ¡ï¼‰
        max_results = request.args.get('maxResults', 20, type=int)
        max_results = min(max_results, 100)  # é™åˆ¶æœ€å¤§100æ¡
        
        print(f"[INFO] æ­£åœ¨è°ƒç”¨ YouTube API è·å– {max_results} æ¡è¯„è®º...")
        # è°ƒç”¨ YouTube API è·å–è¯„è®º
        comments = client.get_video_comments(video_id, max_results=max_results)
        
        if comments:
            print(f"[SUCCESS] æˆåŠŸè·å– {len(comments)} æ¡è¯„è®º")
            return jsonify({
                'success': True,
                'videoId': video_id,
                'comments': comments,
                'total': len(comments)
            })
        else:
            # å¦‚æœè·å–å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
            print("[WARNING] æœªè·å–åˆ°è¯„è®º")
            return jsonify({
                'success': True,
                'videoId': video_id,
                'comments': [],
                'total': 0,
                'message': 'è¯¥è§†é¢‘æ²¡æœ‰è¯„è®ºæˆ–è¯„è®ºå·²å…³é—­'
            })
    except ImportError as e:
        # å¦‚æœæ— æ³•å¯¼å…¥ youtube_clientï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
        print(f"[ERROR] å¯¼å…¥é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'videoId': video_id,
            'comments': [],
            'total': 0,
            'error': str(e),
            'message': 'YouTube API å®¢æˆ·ç«¯å¯¼å…¥å¤±è´¥'
        }), 500
    except ValueError as e:
        # YouTube API å¯†é’¥æœªé…ç½®
        print(f"[ERROR] é…ç½®é”™è¯¯: {str(e)}")
        return jsonify({
            'success': False,
            'videoId': video_id,
            'comments': [],
            'total': 0,
            'error': str(e),
            'message': 'YouTube API å¯†é’¥æœªé…ç½®æˆ–æ— æ•ˆï¼Œè¯·æ£€æŸ¥ config.py'
        }), 500
    except Exception as e:
        print(f"[ERROR] æœªçŸ¥é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'videoId': video_id,
            'error': str(e),
            'error_type': type(e).__name__,
            'message': 'è·å–è¯„è®ºå¤±è´¥ï¼Œè¯·æŸ¥çœ‹åç«¯æ—¥å¿—'
        }), 500


@app.route('/api/videos/<video_id>/comments', methods=['POST'])
def post_comment(video_id):
    """å‘å¸ƒè¯„è®º"""
    data = request.get_json()
    
    if not data or 'comment' not in data:
        return jsonify({'error': 'Comment is required'}), 400
    
    if video_id not in comments_db:
        comments_db[video_id] = []
    
    new_comment = {
        'id': str(int(datetime.now().timestamp() * 1000)),
        'author': data.get('author', 'Anonymous'),
        'text': data['comment'],
        'timestamp': datetime.now().isoformat()
    }
    
    comments_db[video_id].append(new_comment)
    return jsonify(new_comment), 201


@app.route('/api/videos/<video_id>/progress', methods=['GET'])
def get_progress(video_id):
    """è·å–æ’­æ”¾è¿›åº¦"""
    user_progress = progress_db.get(video_id, {'timestamp': 0})
    return jsonify(user_progress)


@app.route('/api/videos/<video_id>/progress', methods=['PUT'])
def update_progress(video_id):
    """æ›´æ–°æ’­æ”¾è¿›åº¦"""
    data = request.get_json()
    
    if not data or 'timestamp' not in data:
        return jsonify({'error': 'Timestamp is required'}), 400
    
    if not isinstance(data['timestamp'], (int, float)):
        return jsonify({'error': 'Invalid timestamp'}), 400
    
    progress_db[video_id] = {
        'timestamp': data['timestamp'],
        'updatedAt': datetime.now().isoformat()
    }
    
    return jsonify({
        'success': True,
        'progress': progress_db[video_id]
    })


@app.route('/api/search', methods=['GET'])
def search():
    """æœç´¢å†…å®¹"""
    query = request.args.get('q', '').lower()
    
    if not query:
        return jsonify({'error': 'Query parameter "q" is required'}), 400
    
    try:
        video_data = load_video_data()
        results = []
        
        for section in video_data.get('sections', []):
            title = section['title'].lower()
            content = section['content'].lower()
            
            if query in title or query in content:
                # æå–åŒ¹é…ç‰‡æ®µ
                index = content.find(query)
                if index != -1:
                    snippet_start = max(0, index - 50)
                    snippet_end = min(len(section['content']), index + len(query) + 50)
                    snippet = '...' + section['content'][snippet_start:snippet_end] + '...'
                else:
                    snippet = section['content'][:100] + '...'
                
                results.append({
                    'videoId': video_data['videoInfo']['videoId'],
                    'sectionId': section['id'],
                    'title': section['title'],
                    'snippet': snippet,
                    'timestamp': section['timestampStart']
                })
        
        return jsonify({
            'results': results,
            'total': len(results)
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        'status': 'ok',
        'timestamp': datetime.now().isoformat(),
        'version': '1.0.0'
    })


# æä¾›é™æ€æ–‡ä»¶
@app.route('/')
def index():
    return send_from_directory(STATIC_DIR, 'index.html')


@app.route('/<path:path>')
def static_files(path):
    return send_from_directory(STATIC_DIR, path)


# é”™è¯¯å¤„ç†
@app.errorhandler(404)
def not_found(error):
    return jsonify({'error': 'Not found'}), 404


@app.errorhandler(500)
def internal_error(error):
    return jsonify({'error': 'Internal server error'}), 500


@app.route('/api/chat', methods=['POST'])
def chat():
    """
    LLM èŠå¤©æ¥å£
    """
    data = request.get_json()

    if not data or 'message' not in data:
        return jsonify({'error': 'Message is required'}), 400
    
    user_message = data['message']
    video_context = data.get('video_context', None)

    try:
        # è°ƒç”¨ Claude API è¿›è¡ŒèŠå¤©
        response = chat_with_openai(user_message, video_context)

        return jsonify({
            'success': True,
            'response': response,
            'timestamp': datetime.now().isoformat()
        })

    except Exception as e:
        return jsonify({
            'error': str(e),
            'response': 'sorry, please try again later.'
        }), 500


@app.route('/api/generate-pdf', methods=['GET'])
def generate_pdf():
    """
    ç”Ÿæˆè§†é¢‘æ•°æ®çš„ PDF æ–‡æ¡£
    """
    try:
        print('[INFO] å¼€å§‹ç”Ÿæˆ PDF...')
        
        # åŠ è½½è§†é¢‘æ•°æ®
        video_data = load_video_data()
        
        # ç”Ÿæˆ PDFï¼ˆåœ¨å†…å­˜ä¸­ï¼‰
        pdf_buffer = generate_video_pdf(video_data, output_path=None)
        
        # ç”Ÿæˆæ–‡ä»¶å
        video_title = video_data.get('videoInfo', {}).get('title', 'video')
        # æ¸…ç†æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦
        safe_title = "".join(c for c in video_title if c.isalnum() or c in (' ', '-', '_')).strip()
        safe_title = safe_title[:50]  # é™åˆ¶é•¿åº¦
        filename = f"{safe_title}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
        
        print(f'[SUCCESS] PDF ç”ŸæˆæˆåŠŸ: {filename}')
        
        # è¿”å› PDF æ–‡ä»¶
        return send_file(
            pdf_buffer,
            mimetype='application/pdf',
            as_attachment=True,
            download_name=filename
        )
        
    except Exception as e:
        print(f'[ERROR] PDF ç”Ÿæˆå¤±è´¥: {str(e)}')
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e),
            'message': 'PDF ç”Ÿæˆå¤±è´¥'
        }), 500

@app.route('/api/video-frame/<video_id>', methods=['GET'])
def get_video_frame(video_id):
    """
    è·å–è§†é¢‘æŒ‡å®šæ—¶é—´æˆ³çš„å¸§å›¾ç‰‡
    
    Query Parameters:
        - timestamp: æ—¶é—´æˆ³ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ä¸º 0
    
    Example:
        GET /api/video-frame/EF8C4v7JIbA?timestamp=1794
    """
    timestamp = request.args.get('timestamp', 0, type=int)
    
    try:
        print(f"[INFO] æ”¶åˆ°å¸§æå–è¯·æ±‚ - è§†é¢‘ID: {video_id}, æ—¶é—´æˆ³: {timestamp}")
        
        # æå–å¸§
        frame_path = extract_frame_at_timestamp(video_id, timestamp)
        
        # è¿”å›å›¾ç‰‡æ–‡ä»¶
        return send_file(
            frame_path,
            mimetype='image/jpeg',
            as_attachment=False,
            download_name=f"frame_{video_id}_{timestamp}.jpg"
        )
        
    except Exception as e:
        print(f"[ERROR] å¸§æå–å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        
        return jsonify({
            'success': False,
            'error': str(e),
            'message': 'æ— æ³•æå–è§†é¢‘å¸§'
        }), 500


@app.route('/api/video-info/<video_id>', methods=['GET'])
def get_video_info(video_id):
    """è·å– YouTube è§†é¢‘ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€æè¿°ç­‰ï¼‰"""
    try:
        print(f"[INFO] è·å–è§†é¢‘ä¿¡æ¯ - è§†é¢‘ID: {video_id}")
        
        import sys
        sys.path.append(str(BASE_DIR))
        from youtube_get_video_information import get_video_information
        
        # è·å–è§†é¢‘ä¿¡æ¯
        video_info = get_video_information(video_id)
        
        if not video_info:
            return jsonify({'success': False, 'message': 'æ— æ³•è·å–è§†é¢‘ä¿¡æ¯'}), 404
        
        print(f"[SUCCESS] è§†é¢‘ä¿¡æ¯è·å–æˆåŠŸ")
        
        return jsonify({
            'success': True,
            'videoId': video_id,
            'title': video_info.get('title', ''),
            'description': video_info.get('description', ''),
            'channelTitle': video_info.get('channel_title', ''),
            'publishedAt': video_info.get('published_at', ''),
            'duration': video_info.get('duration', ''),
            'viewCount': video_info.get('view_count', 0),
            'likeCount': video_info.get('like_count', 0),
            'thumbnail': video_info.get('thumbnails', {}).get('maxres', '')
        })
        
    except Exception as e:
        print(f"[ERROR] è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/video-chapters/<video_id>', methods=['GET'])
def get_video_chapters(video_id):
    """è·å–è§†é¢‘ç« èŠ‚åˆ—è¡¨ï¼ˆç›´æ¥è°ƒç”¨ç°æœ‰å‡½æ•°ï¼‰"""
    try:
        from video_frame_extractor import extract_youtube_chapters
        chapters = extract_youtube_chapters(video_id)
        
        if not chapters:
            return jsonify({'success': False, 'message': 'æœªæ‰¾åˆ°ç« èŠ‚'}), 404
        
        return jsonify({'success': True, 'chapters': chapters, 'total': len(chapters)})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/video-frames/<video_id>', methods=['POST'])
def get_video_frames_batch(video_id):
    """
    æ‰¹é‡è·å–è§†é¢‘å¤šä¸ªæ—¶é—´æˆ³çš„å¸§å›¾ç‰‡
    
    Request Body:
        {
            "timestamps": [10, 30, 60, 120, 180]  // æ—¶é—´æˆ³æ•°ç»„ï¼ˆç§’ï¼‰
        }
    
    Response:
        {
            "success": true,
            "videoId": "xxx",
            "frames": [
                {
                    "timestamp": 10,
                    "success": true,
                    "url": "/api/video-frame/xxx?timestamp=10"
                },
                ...
            ]
        }
    
    Example:
        POST /api/video-frames/EF8C4v7JIbA
        Body: {"timestamps": [10, 30, 60]}
    """
    data = request.get_json()
    
    if not data or 'timestamps' not in data:
        return jsonify({
            'success': False,
            'error': 'timestamps array is required'
        }), 400
    
    timestamps = data['timestamps']
    
    if not isinstance(timestamps, list):
        return jsonify({
            'success': False,
            'error': 'timestamps must be an array'
        }), 400
    
    try:
        print(f"[INFO] æ”¶åˆ°æ‰¹é‡å¸§æå–è¯·æ±‚ - è§†é¢‘ID: {video_id}, æ—¶é—´æˆ³æ•°é‡: {len(timestamps)}")
        
        from video_frame_extractor import extract_multiple_frames
        
        # æå–å¤šä¸ªå¸§
        results = extract_multiple_frames(video_id, timestamps)
        
        # è½¬æ¢ç»“æœæ ¼å¼ï¼Œæ·»åŠ  URL
        frames = []
        for result in results:
            if result['success']:
                frames.append({
                    'timestamp': result['timestamp'],
                    'success': True,
                    'url': f"/api/video-frame/{video_id}?timestamp={result['timestamp']}"
                })
            else:
                frames.append({
                    'timestamp': result['timestamp'],
                    'success': False,
                    'error': result.get('error', 'Unknown error')
                })
        
        success_count = sum(1 for f in frames if f['success'])
        print(f"[SUCCESS] æ‰¹é‡å¸§æå–å®Œæˆ - æˆåŠŸ: {success_count}/{len(timestamps)}")
        
        return jsonify({
            'success': True,
            'videoId': video_id,
            'frames': frames,
            'total': len(frames),
            'successCount': success_count
        })
        
    except Exception as e:
        print(f"[ERROR] æ‰¹é‡å¸§æå–å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        
        return jsonify({
            'success': False,
            'error': str(e),
            'message': 'æ‰¹é‡æå–è§†é¢‘å¸§å¤±è´¥'
        }), 500


@app.route('/api/process-video', methods=['POST'])
def process_video():
    """
    å¤„ç†å‰ç«¯ä¼ æ¥çš„ YouTube è§†é¢‘ URLï¼š
    - æå–è§†é¢‘ ID
    - é€šè¿‡ get_full_transcript è·å–å®Œæ•´å­—å¹•å’Œè§†é¢‘ä¿¡æ¯
    - å°†å­—å¹•å†™å…¥ data/transcript_{video_id}.txt
    - è¿”å›åŸºæœ¬å¤„ç†çŠ¶æ€ç»™å‰ç«¯
    """
    data = request.get_json()

    if not data or 'url' not in data:
        return jsonify({
            'success': False,
            'error': 'URL is required'
        }), 400

    url = data.get('url')

    try:
        print(f"[INFO] å¼€å§‹å¤„ç†è§†é¢‘: {url}")

        import sys
        sys.path.append(str(BASE_DIR))

        from get_full_transcript import get_full_transcript, display_full_transcript
        from youtube_client import YouTubeClient

        # æå–è§†é¢‘ ID
        video_id = YouTubeClient.extract_video_id(url)
        if not video_id:
            return jsonify({
                'success': False,
                'error': 'æ— æ³•ä»URLæå–è§†é¢‘ID'
            }), 400

        print(f"[INFO] æå–åˆ°è§†é¢‘ ID: {video_id}")

        # è·å–å®Œæ•´å­—å¹•ä¸è§†é¢‘è¯¦æƒ…ï¼ˆæ³¨æ„ä¼ å…¥çš„æ˜¯å®Œæ•´ URLï¼‰
        result = get_full_transcript(url, language='en')
        if not result:
            return jsonify({
                'success': False,
                'error': 'æ— æ³•è·å–è§†é¢‘å­—å¹•'
            }), 500

        transcript, details = result

        # ä¿å­˜å­—å¹•åˆ°æ–‡ä»¶ï¼Œä¾›åç»­ /api/videos/<video_id> ä½¿ç”¨
        output_file = DATA_DIR / f"transcript_{video_id}.txt"
        display_full_transcript(transcript, output_file=str(output_file), details=details)

        print(f"[SUCCESS] å­—å¹•å·²å†™å…¥æ–‡ä»¶: {output_file}")

        # è¿™é‡Œæš‚æ—¶ä¸è°ƒç”¨ chat_with_geminiï¼Œé¿å…å¤–éƒ¨ API é€ æˆé˜»å¡æˆ– SSL é”™è¯¯
        # å¦‚éœ€å¯ç”¨ï¼Œå¯åœ¨ä¿è¯ GEMINI_API_KEY å’Œç½‘ç»œç¯å¢ƒæ­£å¸¸åå†è°ƒç”¨
        # optimized = chat_with_gemini({'transcript': transcript, 'details': details})

        return jsonify({
            'success': True,
            'videoId': video_id,
            'title': details.get('title', ''),
            'transcriptLength': len(transcript),
            'message': 'è§†é¢‘å¤„ç†æˆåŠŸ'
        })

    except Exception as e:
        import traceback
        print(f"[ERROR] /api/process-video å¤„ç†å¤±è´¥: {e}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e),
            'message': 'è§†é¢‘å¤„ç†å¤±è´¥'
        }), 500




def chat_with_gemini(video_info):
    """
    ä½¿ç”¨Gemini API è¿›è¡ŒèŠå¤©
    """
    import google.generativeai as genai
    import os
    import json

    gemini_api_key = os.getenv('GEMINI_API_KEY')
    if not gemini_api_key:
        raise ValueError("GEMINI_API_KEY æœªé…ç½®")

    genai.configure(api_key=gemini_api_key)

    # Gemini 2.5 Flash model
    model = genai.GenerativeModel("gemini-2.5-flash")

    system_prompt = """
You are a helpful assistant that can answer questions about the video content.
Please fully optimize and integrate the content provided in the .txt file 
for exapmle:
{
Â  "videoInfo": {
Â  Â  "title": "NVIDIA GTC Washington, D.C. Keynote with CEO Jensen Huang",
Â  Â  "videoId": "IgsA00IsrQo",
Â  Â  "description": "NVIDIA GTC Washington D.C. Keynote - Optimized Transcript",
Â  Â  "thumbnail": "https://img.youtube.com/vi/lQHK61IDFH4/maxresdefault.jpg"
Â  },
Â  "sections": [
Â  Â  {
Â  Â  Â  "id": "section1",
Â  Â  Â  "title": "American Innovation and the AI Revolution",
Â  Â  Â  "timestampStart": "00:00",
Â  Â  Â  "timestampEnd": "02:54",
Â  Â  Â  "content": "America has always been the land of innovation, where invention shaped destiny and technology helped dreams take flight. This history includes foundational breakthroughs like the transistor at Bell Labs, sparking the age of semiconductors and Silicon Valley, Hedy Lamarr's work paving the way for wireless connectivity, the universal computer of IBM's System 360, Intel's microprocessor, and Cray's supercomputers. Later, Apple made computing personal and portable with the iPod and iPhone, while Microsoft opened the window to new software, and ARPANET laid the foundation for the internet. Now, the next era is here, launched by a revolutionary new computing model: **Artificial Intelligence (AI)**. AI is described as the **new industrial revolution** and is considered essential infrastructure, much like electricity and the internet. Every company and nation will build it, and winning this competition will be a test of our capacities unlike anything since the space age. Today, AI factories are rising, built in America for scientists, engineers, and dreamers, clearing the way for abundance, saving lives, and extending humanity's reach to the stars in what is called America's next Apollo moment."
Â  Â  },
Â  Â  {
Â  Â  Â  "id": "section2",
Â  Â  Â  "title": "Welcome to GTC and the End of Moore's Law",
Â  Â  Â  "timestampStart": "02:54",
Â  Â  Â  "timestampEnd": "07:36",
Â  Â  Â  "content": "Jensen Huang welcomed the GTC audience in Washington D.C., emphasizing that the conference is where industry, science, computing, the present, and the future converge. He introduced the core innovation: the **Accelerated Computing** model, the first new computing model in 60 years. This model was invented to solve problems that general-purpose computers, or \"normal computers,\" could not. The need for this shift arose because the slowing down of Dennard Scaling and Moore's Law, limited by the laws of physics, is now a reality. While the number of transistors continues to grow, the performance and power efficiency have slowed tremendously. For 30 years, NVIDIA has advanced Accelerated Computing, inventing the **GPU** and the programming model **CUDA**. The core observation was that adding a parallel-processing GPU to a sequential-processing CPU could extend the capabilities of computing well beyond what was previously possible, and that inflection point has now arrived."
Â  Â  },
Â  Â  {
Â  Â  Â  "id": "section3",
Â  Â  Â  "title": "The CUDA-X Ecosystem and 30 Years of Libraries",
Â  Â  Â  "timestampStart": "07:36",
Â  Â  Â  "timestampEnd": "15:07",
Â  Â  Â  "content": "Accelerated computing is a fundamentally different programming model; simply moving sequential CPU software to a GPU will, in fact, make it run slower. This required the **reinvention of new algorithms and libraries**, and the rewriting of applicationsâ€”a 30-year effort that was tackled one domain at a time. The real treasure of NVIDIA is not just the GPU, but the programming model **CUDA**, which has been kept compatible over generations (now on the cusp of CUDA 14), and the vast ecosystem of libraries known as **CUDA-X**. These libraries, which redesign algorithms for accelerated computing, open new markets and enable the entire ecosystem. Key examples include **cuLitho** for computational lithography (used by TSMC, Samsung, ASML), **cuOpt** for numerical optimization (breaking records in problems like the traveling salesperson problem), **QDF** for accelerating data frame databases, and **Megatron Core** for training extremely large language models. The list also includes **Monai** (the number one medical imaging AI framework) and **cuQuantum** for quantum computing. A demonstration showed that CUDA-X enables simulation across every industryâ€”from healthcare and life sciences to robotics, autonomous vehicles, and computer graphicsâ€”all powered by the beauty of mathematics and deep computer science."
Â  Â  },
Â  Â  {
Â  Â  Â  "id": "section4",
Â  Â  Â  "title": "NVIDIA Arc and the 6G Telecommunications Platform",
Â  Â  Â  "timestampStart": "15:07",
Â  Â  Â  "timestampEnd": "21:33",
Â  Â  Â  "content": "Telecommunications is the lifeblood of our economy and national security, but wireless technology has largely been deployed on foreign standards for a long time. This fundamental platform shift presents a once-in-a-lifetime opportunity for American technology to get back into the game. NVIDIA is partnering with **Nokia**, the second-largest telecommunications maker in the world, to be at the center of the next revolution in **6G**. The new product line is the **NVIDIA Arc (Aerial Radio Network Computer)**, built from the **Grace CPU**, **Blackwell GPU**, and **ConnectX** networking, and running the **Aerial** CUDA-X library. Arc creates a **software-defined programmable computer** capable of both wireless communication and AI processing. Nokia will make Arc its future base station, which is compatible with their current Airscale stations, allowing millions of base stations globally to be upgraded with 6G and AI. The two fundamental benefits are **AI for RAN** (Radio Access Network) and **AI on RAN**. AI for RAN uses reinforcement learning to dynamically adjust beamforming and traffic, which improves spectral efficiency and reduces the world's power consumption (currently 1.5-2%). AI on RAN creates a brand new opportunity: an **edge industrial robotics cloud** on top of the wireless network, essentially extending cloud computing to the edge where base stations exist."
Â  Â  },
Â  Â  {
Â  Â  Â  "id": "section5",
Â  Â  Â  "title": "NVQLink: Hybrid Quantum-GPU Supercomputing",
Â  Â  Â  "timestampStart": "21:33",
Â  Â  Â  "timestampEnd": "30:36",
Â  Â  Â  "content": "The pursuit of quantum computing, first imagined by Richard Feynman in 1981 to simulate nature, recently reached a fundamental breakthrough: the ability to create one stable, error-corrected **logical qubit** (which itself consists of tens or hundreds of fragile physical qubits). To manage the instability and perform the trillions of operations required for meaningful problem-solving, a new solution is necessary: directly connecting a quantum computer (QPU) to a **GPU supercomputer**. NVIDIA's answer is **NVQLink**, a new interconnect architecture that performs **quantum error correction**, control, and calibration, and co-simulations by connecting the two computers side-by-side. NVQLink is capable of moving terabytes of data thousands of times per second, which is essential for error correction and scaling quantum computers from hundreds to hundreds of thousands of qubits in the future. The open platform at its heart is **CUDA-Q**, which extends the CUDA model to support the QPU. This vision is supported by 17 different quantum computer companies and eight DOE labs (including Berkeley, Los Alamos, and Oak Ridge) to integrate quantum computing into the future of science. In a major announcement, the Department of Energy is partnering with NVIDIA to build **seven new AI supercomputers** to advance US science, embracing the simultaneous platform shifts to accelerated computing, AI-enhanced principal solvers, quantum computing, and robotic laboratories."
Â  Â  },
Â  Â  {
Â  Â  Â  "id": "section6",
Â  Â  Â  "title": "AI: Reinventing the Computing Stack as 'Work'",
Â  Â  Â  "timestampStart": "30:36",
Â  Â  Â  "timestampEnd": "39:20",
Â  Â  Â  "content": "While chatbots are the public face of AI, the world of AI is much more, extending to basic science, AGI, and every industry. Fundamentally, AI has **completely reinvented the computing stack**. Software has shifted from hand-coding on CPUs to machine learning, data-intensive programming trained and learned by AI running on GPUs. This new stack requires enormous amounts of energy, which GPU supercomputers transform into **tokens**â€”the computational unit and vocabulary of artificial intelligence. Anything with structure and information content can be tokenized, including English words, images, video, 3D structures (like factories), chemicals, proteins, and genes. Once tokenized, AI can learn the language and meaning to translate, respond, and generate, just as ChatGPT does. The profound difference is that **AI is not a tool; AI is work**. The software industry of the past created tools (like Excel or a web browser) that humans used. AI, conversely, creates **workers**â€”agentic AI systems (like Perplexity or the developer partner Cursor)â€”that can actually use tools to perform tasks. This monumental shift allows AI to address a segment of the economy it has never touched, augmenting labor and engaging the **$100 trillion global economy** to make it more productive. Furthermore, AI itself is a **new industry**: an \"AI factory\" designed to produce these smart tokens."
Â  Â  },
Â  Â  {
Â  Â  Â  "id": "section7",
Â  Â  Â  "title": "The AI Factory and the Three New Scaling Laws",
Â  Â  Â  "timestampStart": "39:20",
Â  Â  Â  "timestampEnd": "45:00",
Â  Â  Â  "content": "The immense computational need for AI has necessitated the invention of the **AI factory**, a new type of system unlike the general-purpose data centers of the past. This factory is designed primarily to run AI and produce high-value, smart tokens at incredible rates for immediate response. The explosion of AI is driven by three new scaling laws: The first is **Scale**, involving larger models with more data and parameters, like the concept of a multi-trillion dollar AI model. The second is **Post-Training**, which moves beyond pre-training (the basic memorization and generalization akin to preschool) to teach the AI essential skills like problem-solving, coding, reasoning, and thinking about problems step-by-step using **first-principle reasoning**. The third, and most computationally demanding, is **Inference**, or thinking. When an AI acts as an agentâ€”breaking down problems, reasoning, planning, and executingâ€”it requires an enormous number of tokens to be generated. Thinking is hard, which is why the computation necessary for AI to think on behalf of every human has put extraordinary pressure on the infrastructure."
Â  Â  },
Â  Â  {
Â  Â  Â  "id": "section8",
Â  Â  Â  "title": "Extreme Co-Design and Manufacturing the Rubin Platform in America",
Â  Â  Â  "timestampStart": "45:00",
Â  Â  Â  "timestampEnd": "01:09:51",
Â  Â  Â  "content": "To achieve the necessary scale and performance, NVIDIA has pioneered **extreme co-design** in its infrastructure. They use **NVLink** to create one giant fabric where the entire multi-trillion parameter model, broken into \"experts,\" can communicate efficiently. This architecture is enabled by the custom **Spectrum Ethernet** (Spectrum X) designed specifically for AI performance, which is then scaled across multiple data centers via **Spectrum XGS (Gigascale X)**. This code-design is so extreme that it delivers \"shocking\" generational performance benefitsâ€”much more than typical gains. The latest platform is the **Rubin platform** (the third generation NVLink 72 rack scale computer), a system that has been \"ground up, reinvented\" since the IBM System 360. This new node, completely cableless and **100% liquid-cooled**, features the **ConnectX-9**, **BlueField-4 DPU**, **Vera CPUs**, and **Rubin GPUs**, delivering 100 times the performance of the DGX-1 delivered just nine years ago. Critically, NVIDIA is also manufacturing the **Blackwell** and future generations of these AI factory systems in America, with production starting in Arizona, Indiana, and Texas, fulfilling the call to **bring manufacturing back** for national security and reindustrialization."
Â  Â  },
Â  Â  {
Â  Â  Â  "id": "section9",
Â  Â  Â  "title": "AI Agents and the Transformation of Enterprise",
Â  Â  Â  "timestampStart": "01:09:51",
Â  Â  Â  "timestampEnd": "01:26:21",
Â  Â  Â  "content": "The next frontier for this powerful computing is the **Enterprise**, where workloads and workflows will transition to **Agentic SaaS (Software as a Service)**. NVIDIA is partnering with industry leaders to integrate its libraries (CUDA-X, Nemo, NeMo-Triton) and AI systems to create AI agents and accelerate platforms across the global economy. Key partnerships include: **ServiceNow**, which handles 85% of the world's enterprise workflows; **SAP**, which facilitates 80% of the world's commerce; and major EDA/CAD firms like **Synopsis** and **Cadence**, accelerating their stacks and working towards having AI agent ASIC and system designers. Furthermore, recognizing that AI will supercharge cyber security challenges, NVIDIA is partnering with **CrowdStrike** to build an incredible defender platform. Finally, a partnership with **Palantir** will accelerate everything they do, allowing for data processing and business insightâ€”for both structured and unstructured dataâ€”at the speed of light for government and enterprises globally."
Â  Â  },
Â  Â  {
Â  Â  Â  "id": "section10",
Â  Â  Â  "title": "Conclusion: Two Platform Transitions and the Future",
Â  Â  Â  "timestampStart": "01:26:21",
Â  Â  Â  "timestampEnd": "01:42:25",
Â  Â  Â  "content": "In closing, the world is experiencing an extraordinary period of growth fueled by two concurrent platform transitions. The first is the inflection point of **Accelerated Computing**, and the second is the fundamental transition of software to **Artificial Intelligence**. The new platforms introducedâ€”**ARC** for 6G, **Hyperion** for robotics cars, **DSX** for the AI factory, and **Mega** for factories with AIâ€”demonstrate this comprehensive transformation. NVIDIA celebrates the return of manufacturing and the building of these technologies in America, marking a new chapter in industry and history. The keynote concludes by thanking the attendees for their service and for allowing GTC to be hosted in Washington D.C."
Â  Â  }
Â  ]
}
    """

    response = model.generate_content(system_prompt, video_info)

    json = json.loads(response.choices[0].message.content)

    print(f"video data json information: {json}")
    return json



def chat_with_openai(user_message, video_context):
    """
    ä½¿ç”¨Open AI (æ–°ç‰ˆ API >= 1.0.0)
    """
    from openai import OpenAI
    import os

    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = OpenAI(
        api_key=os.getenv('OPENAI_API_KEY')
    )
    
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªè§†é¢‘åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·ç†è§£å’ŒæŸ¥æ‰¾è§†é¢‘å†…å®¹ã€‚
å½“å‰è§†é¢‘æ˜¯å…³äº NVIDIA GTC å¤§ä¼šçš„ä¸»é¢˜æ¼”è®²ï¼Œæ¶µç›–äº† AIã€åŠ é€Ÿè®¡ç®—ã€é‡å­è®¡ç®—ç­‰ä¸»é¢˜ã€‚
è¯·ç”¨ç®€æ´ã€å‹å¥½çš„æ–¹å¼å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"""
    
    messages = [
        {"role": "system", "content": system_prompt}
    ]
    
    if video_context:
        messages.append({
            "role": "system",
            "content": f"è§†é¢‘ä¿¡æ¯ï¼š{json.dumps(video_context, ensure_ascii=False)}"
        })
    
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    messages.append({"role": "user", "content": user_message})
    
    # è°ƒç”¨ OpenAI API (æ–°ç‰ˆ)
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages,
        max_tokens=500,
        temperature=0.7
    )
    
    return response.choices[0].message.content

if __name__ == '__main__':
    print('ğŸš€ Server is running on http://localhost:5000')
    print('ğŸ“Š API endpoint: http://localhost:5000/api')
    print('ğŸŒ Frontend: http://localhost:5000/index.html')
    app.run(debug=True, host='0.0.0.0', port=5000)

