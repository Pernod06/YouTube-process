"""
LangChain Server - OpenRouter Integration
"""
import os

from typing import Optional, Dict, Any, List, AsyncIterator
import json
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from collections import deque

# OpenRouter é…ç½®
OPENROUTER_BASE_URL = "https://openrouter.ai/api/v1"

# == Pydantic è¾“å‡ºæ¨¡å‹ ==

class ContentItem(BaseModel):
    content: str = Field(description="å…³é”®ç‚¹å†…å®¹ï¼ˆ1-2å¥è¯ï¼‰")
    timestampStart: str = Field(description="æ—¶é—´æˆ³ï¼Œæ ¼å¼ï¼š HH:MM:SS")

class Section(BaseModel):
    """è§†é¢‘ç« èŠ‚"""
    id: str = Field(description="ç« èŠ‚ IDï¼Œå¦‚ section1")
    title: str = Field(description="ç« èŠ‚æ ‡é¢˜")
    content: List[ContentItem] = Field(description="ç« èŠ‚å†…å®¹åˆ—è¡¨")

class VideoInfo(BaseModel):
    """è§†é¢‘åŸºæœ¬ä¿¡æ¯"""
    title: str = Field(description="è§†é¢‘æ ‡é¢˜")
    videoId: str = Field(description="è§†é¢‘ ID")
    description: str = Field(description="ç®€çŸ­æè¿°")
    thumbnail: str = Field(description="ç¼©ç•¥å›¾ URL")
    summary: str = Field(description="2-3å¥è¯æ€»ç»“")

class VideoAnalysisResult(BaseModel):
    """è§†é¢‘åˆ†æç»“æœ"""
    videoInfo: VideoInfo
    sections: List[Section] = Field(description="è§†é¢‘ç« èŠ‚åˆ—è¡¨")

class Theme(BaseModel):
    """è§†é¢‘ä¸»é¢˜ - è·¨ç« èŠ‚èšåˆçš„å†…å®¹ä¸»é¢˜"""
    id: str = Field(description="ä¸»é¢˜ IDï¼Œå¦‚ theme1")
    title: str = Field(description="ä¸»é¢˜æ ‡é¢˜")
    description: str = Field(description="ä¸»é¢˜ç®€è¦æè¿°")
    content: List[ContentItem] = Field(description="è¯¥ä¸»é¢˜ç›¸å…³çš„å†…å®¹åˆ—è¡¨ï¼Œä»å„ç« èŠ‚èšåˆ")

class ThemeResult(BaseModel):
    """ä¸»é¢˜ç”Ÿæˆç»“æœ"""
    themes: List[Theme] = Field(description="2-5ä¸ªä¸»é¢˜åˆ—è¡¨")

# ========= LLM Server =========

class LLMService:
    """ç»Ÿä¸€ LLM æœåŠ¡ - OpenRouter"""
    def __init__(self):
        api_key = os.getenv('OPENROUTER_API_KEY')
        if not api_key:
            raise ValueError("OPENROUTER_API_KEY is not set")
        
        # ä¸»æ¨¡å‹ (ç”¨äºå¤æ‚ä»»åŠ¡ï¼Œtranscriptè§£æ)
        # OpenRouter æ¨¡å‹æ ¼å¼: provider/model-name
        self.llm = ChatOpenAI(
            api_key=api_key,
            base_url=OPENROUTER_BASE_URL,
            model="google/gemini-2.5-flash-lite",  # æˆ– "anthropic/claude-3.5-sonnet"
            temperature=0.3,
            streaming=True,
            default_headers={
                "HTTP-Referer": "https://your-app.com",  # å¯é€‰ï¼šä½ çš„åº”ç”¨ URL
                "X-Title": "YouTube Process API",        # å¯é€‰ï¼šåº”ç”¨åç§°
            }
        )

        # è½»é‡æ¨¡å‹ ç”¨äºchatå’Œç¿»è¯‘
        self.llm_lite = ChatOpenAI(
            api_key=api_key,
            base_url=OPENROUTER_BASE_URL,
            model="google/gemini-2.5-flash-lite",  # æˆ– "openai/gpt-4o-mini"
            temperature=0.7,
            default_headers={
                "HTTP-Referer": "https://your-app.com",
                "X-Title": "YouTube Process API",
            }
        )

        # èŠå¤©è®°å½•ï¼ˆä¿ç•™æœ€è¿‘å¯¹è¯ï¼‰- ä½¿ç”¨ç®€å•çš„ deque å®ç°
        self._chat_memories: Dict[str, deque] = {}
        self._memory_window_size = 5  # ä¿ç•™æœ€è¿‘5è½®å¯¹è¯

    def _get_memory(self, video_id: str, user_id: str = "anonymous") -> deque:
        """è·å–æˆ–åˆ›å»ºç”¨æˆ·+è§†é¢‘çš„èŠå¤©è®°å½•ï¼ˆç”¨æˆ·éš”ç¦»ï¼‰"""
        memory_key = f"{user_id}:{video_id}"
        if memory_key not in self._chat_memories:
            self._chat_memories[memory_key] = deque(maxlen=self._memory_window_size * 2)
        return self._chat_memories[memory_key]
    
    def _add_to_memory(self, video_id: str, user_id: str, human_msg: str, ai_msg: str):
        """æ·»åŠ å¯¹è¯åˆ°è®°å¿†"""
        memory = self._get_memory(video_id, user_id)
        memory.append(HumanMessage(content=human_msg))
        memory.append(AIMessage(content=ai_msg))
    
    def _get_memory_messages(self, video_id: str, user_id: str = "anonymous") -> List:
        """è·å–è®°å¿†ä¸­çš„æ¶ˆæ¯åˆ—è¡¨"""
        memory = self._get_memory(video_id, user_id)
        return list(memory)
    
    def clear_user_memory(self, video_id: str, user_id: str = "anonymous"):
        """æ¸…é™¤æŒ‡å®šç”¨æˆ·çš„è§†é¢‘èŠå¤©è®°å½•"""
        memory_key = f"{user_id}:{video_id}"
        if memory_key in self._chat_memories:
            del self._chat_memories[memory_key]


    # ==== transcript åˆ†æ Chain ====
    def analyze_video_transcript(
        self,
        transcript: List[str],
        details: dict,
        video_id: str,
    ) -> VideoAnalysisResult:
        """
        åˆ†æè§†é¢‘å­—å¹•å¹¶ç”Ÿæˆç»“æ„åŒ–ç»“æœ
        ä½¿ç”¨ LangChain çš„ pydanticOutputParser ç¡®ä¿è¾“å‡ºæ ¼å¼æ­£ç¡®
        """
        def seconds_to_timestamp(seconds):
            total = int(float(seconds))
            h, m, s = total // 3600, (total % 3600) // 60, total % 60
            return f"{h:02d}:{m:02d}:{s:02d}"

        transcript_text = "\n".join([
            f"[{seconds_to_timestamp(item['start'])}] {item['text']}"
            for item in transcript
        ])

        transcript_preview = self._sample_transcript(transcript_text)

        parser = PydanticOutputParser(pydantic_object=VideoAnalysisResult)

        # åˆ›å»º Prompt æ¨¡æ¿
        prompt = ChatPromptTemplate.from_messages([
            ("system", """You are an expert video content analyst. Analyze this YouTube video transcript and extract valuable insights.

**SUMMARIZE, DON'T TRANSCRIBE**: Extract insights, arguments, and conclusions - NOT word-for-word transcript.

{format_instructions}

REQUIREMENTS:
- Cover the ENTIRE video from beginning to end
- Create sections based on natural topic changes
- Each content item: 1-2 concise sentences
- timestampStart format: "HH:MM:SS"
- COPY timestamps EXACTLY from the transcript"""),
            ("human", """Video Title: {title}
Video ID: {video_id}
Thumbnail: {thumbnail}

Transcript:
{transcript}""")
        ])

        # åˆ›å»º Chain
        chain = prompt | self.llm | parser

        # run
        result = chain.invoke({
            "title": details.get('title', 'Unknown'),
            "video_id": video_id,
            "thumbnail": f"https://img.youtube.com/vi/{video_id}/maxresdefault.jpg",
            "transcript": transcript_preview,
            "format_instructions": parser.get_format_instructions(),
        })

        return result

    async def analyze_video_transcript_stream(
        self,
        transcript: List[dict],
        details: dict,
        video_id: str,
    ) -> AsyncIterator[str]:
        """
        æµå¼åˆ†æè§†é¢‘å­—å¹•ï¼Œé€æ­¥è¾“å‡ºç”Ÿæˆçš„ JSON
        
        Yields:
            str: æµå¼è¾“å‡ºçš„æ–‡æœ¬å—ï¼ˆJSON ç‰‡æ®µï¼‰
        """
        def seconds_to_timestamp(seconds):
            total = int(float(seconds))
            h, m, s = total // 3600, (total % 3600) // 60, total % 60
            return f"{h:02d}:{m:02d}:{s:02d}"

        transcript_text = "\n".join([
            f"[{seconds_to_timestamp(item['start'])}] {item['text']}"
            for item in transcript
        ])

        transcript_preview = self._sample_transcript(transcript_text)

        # ä¸ä½¿ç”¨ PydanticOutputParserï¼Œç›´æ¥æµå¼è¾“å‡º
        prompt = ChatPromptTemplate.from_messages([
            ("system", """You are an expert video content analyst. Analyze this YouTube video transcript and extract valuable insights.

**SUMMARIZE, DON'T TRANSCRIBE**: Extract insights, arguments, and conclusions - NOT word-for-word transcript.

Generate JSON with this EXACT structure:
{{
  "videoInfo": {{
    "title": "Video Title",
    "videoId": "{video_id}",
    "description": "Brief topic description",
    "thumbnail": "https://img.youtube.com/vi/{video_id}/maxresdefault.jpg",
    "summary": "2-3 sentence summary"
  }},
  "sections": [
    {{
      "id": "section1",
      "title": "Section Title",
      "content": [
        {{"content": "Key point (1-2 sentences)", "timestampStart": "00:00:00"}}
      ]
    }}
  ]
}}

REQUIREMENTS:
- Cover the ENTIRE video from beginning to end
- Create sections based on natural topic changes
- Each content item: 1-2 concise sentences
- timestampStart format: "HH:MM:SS"
- COPY timestamps EXACTLY from the transcript
- Output valid JSON only, no markdown code blocks"""),
            ("human", """Video Title: {title}
Video ID: {video_id}
Thumbnail: {thumbnail}

Transcript:
{transcript}""")
        ])

        # æµå¼è¾“å‡º
        print(f"[LLM] å¼€å§‹æµå¼è°ƒç”¨...", flush=True)
        full_response = ""
        chunk_idx = 0
        async for chunk in (prompt | self.llm).astream({
            "title": details.get('title', 'Unknown'),
            "video_id": video_id,
            "thumbnail": f"https://img.youtube.com/vi/{video_id}/maxresdefault.jpg",
            "transcript": transcript_preview,
        }):
            content = chunk.content if hasattr(chunk, 'content') else str(chunk)
            if content:
                chunk_idx += 1
                full_response += content
                # è°ƒè¯•å‰å‡ ä¸ª chunks
                if chunk_idx <= 5:
                    print(f"[LLM] chunk#{chunk_idx} é•¿åº¦:{len(content)} å†…å®¹å‰50å­—ç¬¦:{repr(content[:50])}", flush=True)
                yield content
        
        print(f"[LLM] æµå¼å®Œæˆï¼Œæ€»chunks:{chunk_idx}, æ€»é•¿åº¦:{len(full_response)}", flush=True)
        # æµå¼ç»“æŸæ ‡è®°ï¼ˆç”¨äºå‰ç«¯åˆ¤æ–­ï¼‰
        yield "\n[STREAM_END]"

    def parse_analysis_result(self, raw_text: str) -> VideoAnalysisResult:
        """
        è§£ææµå¼è¾“å‡ºçš„ç»“æœä¸ºç»“æ„åŒ–å¯¹è±¡
        
        Args:
            raw_text: LLM ç”Ÿæˆçš„åŸå§‹ JSON æ–‡æœ¬
            
        Returns:
            VideoAnalysisResult: è§£æåçš„ç»“æ„åŒ–ç»“æœ
        """
        # æ¸…ç†æ–‡æœ¬
        import re
        text = re.sub(r'^```json?\s*', '', raw_text.strip())
        text = re.sub(r'\s*```$', '', text)
        text = text.replace('[STREAM_END]', '').strip()
        
        # æå– JSON
        start = text.find('{')
        if start == -1:
            raise ValueError("No JSON found in response")
        
        brace_count = 0
        end = start
        for i, c in enumerate(text[start:], start):
            if c == '{': brace_count += 1
            elif c == '}': 
                brace_count -= 1
                if brace_count == 0:
                    end = i + 1
                    break
        
        json_str = text[start:end]
        data = json.loads(json_str)
        
        # è½¬æ¢ä¸º Pydantic æ¨¡å‹
        return VideoAnalysisResult(**data)


    # === chat ===

    def chat_with_video(
        self, 
        user_message: str, 
        video_context: Optional[Dict[str, Any]] = None,
        video_id: str = "default",
        user_id: str = "anonymous"
    ) -> str:
        """
        åŸºäºè§†é¢‘å†…å®¹çš„èŠå¤©ï¼Œæ”¯æŒå¯¹è¯è®°å¿†ï¼ˆç”¨æˆ·éš”ç¦»ï¼‰
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            video_context: è§†é¢‘ä¸Šä¸‹æ–‡ä¿¡æ¯
            video_id: è§†é¢‘ ID
            user_id: ç”¨æˆ·æ ‡è¯†ï¼ˆç”¨äºéš”ç¦»ä¸åŒç”¨æˆ·çš„èŠå¤©è®°å½•ï¼‰
        """
        system_prompt = """You are PageOn-Video assistant, helping users understand video content.

Your abilities:
1. **Deep Analysis**: Provide accurate responses based on video transcript and chapters
2. **Time Clips**: Identify precise video segments with start and end timestamps
3. **Contextual Understanding**: Comprehend overall video structure

Response Format:
- When referencing video moments, use TIME CLIPS format:
[START - END] Description
  Example: [02:30 - 04:15] Explanation of the main concept
  
- For single moments: [05:30] Brief description
- List all relevant clips if topic appears multiple times
- Be concise yet informative
- Friendly and professional tone

Example Response:
"The video discusses AI in these segments:
[01:20 - 03:45] Introduction to machine learning basics
[08:10 - 12:30] Deep learning applications
[15:00 - 15:45] Future predictions"
"""

        # æ„å»º prompt
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "Video Context: {video_context}\n\nUser Question: {question}"),
        ])

        # è·å–ç”¨æˆ·+è§†é¢‘çš„ç‹¬ç«‹è®°å¿†
        chat_history = self._get_memory_messages(video_id, user_id)

        # åˆ›å»º Chain
        chain = prompt | self.llm_lite | StrOutputParser()

        # run
        result = chain.invoke({
            "video_context": str(video_context) if video_context else "No context",
            "question": user_message,
            "chat_history": chat_history,
        })

        # ä¿å­˜åˆ°è®°å¿†
        self._add_to_memory(video_id, user_id, user_message, result)

        return result


    # ==== translate ====

    def translate_video_data(
        self, 
        cached_data: dict, 
        target_language_code: str
    ) -> dict:
        """
        ç¿»è¯‘è§†é¢‘æ•°æ®åˆ°ç›®æ ‡è¯­è¨€
        """
        import json
        
        language_names = {
            "zh": "Chinese (ç®€ä½“ä¸­æ–‡)",
            "en": "English",
            "ja": "Japanese (æ—¥æœ¬èª)",
            "ko": "Korean (í•œêµ­ì–´)",
            "es": "Spanish (EspaÃ±ol)",
            "fr": "French (FranÃ§ais)",
            "de": "German (Deutsch)",
        }
        target_lang = language_names.get(target_language_code, "English")
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a professional translator. 
Translate ALL text content in the JSON to {target_language}.

CRITICAL - YOU MUST TRANSLATE:
- videoInfo.title (è§†é¢‘æ ‡é¢˜ - MUST be translated!)
- videoInfo.description
- videoInfo.summary
- All sections[].title
- All sections[].content
- All chapters[].title (if exists)

DO NOT TRANSLATE (keep original):
- videoId, id, thumbnail, thumbnail_url
- timestampStart, timestamp, any numbers/URLs

OUTPUT:
- Return the complete JSON with translated text
- Keep exact same structure
- Output valid JSON only, no explanation"""),
            ("human", "{json_data}")
        ])
        
        chain = prompt | self.llm_lite | StrOutputParser()
        
        print(f"[Translate] ğŸ”„ å¼€å§‹ç¿»è¯‘åˆ° {target_lang}...")
        print(f"[Translate] ğŸ“ åŸå§‹æ ‡é¢˜: {cached_data.get('videoInfo', {}).get('title', 'N/A')[:50]}...")
        
        response = chain.invoke({
            "target_language": target_lang,
            "json_data": json.dumps(cached_data, ensure_ascii=False)
        })
        
        print(f"[Translate] ğŸ“¥ LLM å“åº”é•¿åº¦: {len(response)}")
        print(f"[Translate] ğŸ“¥ LLM å“åº”å‰200å­—ç¬¦: {response[:200]}...")
        
        # è§£æ JSON
        result = self._extract_json(response)
        
        if not result:
            print(f"[Translate] âŒ JSON è§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹æ•°æ®")
            return cached_data
        
        print(f"[Translate] âœ… ç¿»è¯‘å®Œæˆï¼Œæ ‡é¢˜: {result.get('videoInfo', {}).get('title', 'N/A')[:50]}...")
        return result


    # ==== theme ç”Ÿæˆ ====
    
    # è¯­è¨€åç§°æ˜ å°„
    LANGUAGE_NAMES = {
        "zh": "Chinese (ç®€ä½“ä¸­æ–‡)",
        "en": "English",
        "ja": "Japanese (æ—¥æœ¬èª)",
        "ko": "Korean (í•œêµ­ì–´)",
        "es": "Spanish (EspaÃ±ol)",
        "fr": "French (FranÃ§ais)",
        "de": "German (Deutsch)",
    }

    def generate_themes(
        self,
        video_data: dict,
        language: str = "en",
    ) -> ThemeResult:
        """
        æ ¹æ®è§†é¢‘åˆ†æ JSON ç”Ÿæˆ 2-5 ä¸ªä¸»é¢˜
        
        Args:
            video_data: è§†é¢‘åˆ†æç»“æœ JSONï¼ŒåŒ…å« videoInfo å’Œ sections
            language: è¾“å‡ºè¯­è¨€ä»£ç ï¼ˆé»˜è®¤è‹±è¯­ï¼‰
            
        Returns:
            ThemeResult: åŒ…å« 2-5 ä¸ªä¸»é¢˜çš„ç»“æœ
        """
        parser = PydanticOutputParser(pydantic_object=ThemeResult)
        target_lang = self.LANGUAGE_NAMES.get(language, "English")
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """You are an expert content analyst. Analyze the video content and identify 2-5 major THEMES.

**OUTPUT LANGUAGE**: Generate ALL text content (title, description, content) in {target_language}.

**THEME vs SECTION**: 
- Sections are chronological (time-based)
- Themes are conceptual (topic-based, cross-cutting)

**Your Task**:
1. Identify 2-5 distinct themes based on content richness
2. For each theme, aggregate relevant content from ALL sections
3. Keep original timestamps for each content item

{format_instructions}

**REQUIREMENTS**:
- Generate 2-5 themes based on content depth (more content = more themes)
- Each theme should have a clear, descriptive title IN {target_language}
- Include a brief description explaining the theme IN {target_language}
- Aggregate content items from different sections if they relate to the same theme
- ALL content text must be in {target_language}
- Preserve original timestampStart values (do NOT translate timestamps)
- Theme IDs: theme1, theme2, etc."""),
            ("human", """Video Title: {title}

Video Content (sections):
{sections_json}

Generate themes in {target_language}:""")
        ])
        
        chain = prompt | self.llm | parser
        
        # å‡†å¤‡ sections JSON
        sections_json = json.dumps(video_data.get('sections', []), ensure_ascii=False, indent=2)
        
        result = chain.invoke({
            "title": video_data.get('videoInfo', {}).get('title', 'Unknown'),
            "sections_json": sections_json,
            "format_instructions": parser.get_format_instructions(),
            "target_language": target_lang,
        })
        
        return result

    async def generate_themes_stream(
        self,
        video_data: dict,
        language: str = "en",
    ) -> AsyncIterator[str]:
        """
        æµå¼ç”Ÿæˆä¸»é¢˜
        
        Args:
            video_data: è§†é¢‘åˆ†æç»“æœ JSON
            language: è¾“å‡ºè¯­è¨€ä»£ç ï¼ˆé»˜è®¤è‹±è¯­ï¼‰
            
        Yields:
            str: æµå¼è¾“å‡ºçš„ JSON ç‰‡æ®µ
        """
        target_lang = self.LANGUAGE_NAMES.get(language, "English")
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """You are an expert content analyst. Analyze the video content and identify 2-5 major THEMES.

**OUTPUT LANGUAGE**: Generate ALL text content (title, description, content) in {target_language}.

**THEME vs SECTION**: 
- Sections are chronological (time-based)
- Themes are conceptual (topic-based, cross-cutting)

Generate JSON with this EXACT structure:
{{
  "themes": [
    {{
      "id": "theme1",
      "title": "Theme Title in {target_language}",
      "description": "Brief description in {target_language}",
      "content": [
        {{"content": "Key point in {target_language}", "timestampStart": "00:05:30"}}
      ]
    }}
  ]
}}

**REQUIREMENTS**:
- Generate 2-5 themes based on content depth
- Each theme: clear title + description + aggregated content
- ALL text must be in {target_language}
- Preserve original timestampStart values (do NOT translate timestamps)
- Output valid JSON only, no markdown code blocks"""),
            ("human", """Video Title: {title}

Video Content (sections):
{sections_json}

Generate themes in {target_language}:""")
        ])
        
        sections_json = json.dumps(video_data.get('sections', []), ensure_ascii=False, indent=2)
        
        print(f"[LLM] å¼€å§‹æµå¼ç”Ÿæˆä¸»é¢˜ï¼Œè¯­è¨€: {target_lang}...", flush=True)
        full_response = ""
        chunk_idx = 0
        
        async for chunk in (prompt | self.llm).astream({
            "title": video_data.get('videoInfo', {}).get('title', 'Unknown'),
            "sections_json": sections_json,
            "target_language": target_lang,
        }):
            content = chunk.content if hasattr(chunk, 'content') else str(chunk)
            if content:
                chunk_idx += 1
                full_response += content
                if chunk_idx <= 3:
                    print(f"[LLM] theme chunk#{chunk_idx}: {repr(content[:50])}", flush=True)
                yield content
        
        print(f"[LLM] ä¸»é¢˜ç”Ÿæˆå®Œæˆï¼Œæ€»chunks:{chunk_idx}", flush=True)
        yield "\n[STREAM_END]"

    def parse_themes_result(self, raw_text: str) -> ThemeResult:
        """
        è§£ææµå¼è¾“å‡ºçš„ä¸»é¢˜ç»“æœ
        
        Args:
            raw_text: LLM ç”Ÿæˆçš„åŸå§‹ JSON æ–‡æœ¬
            
        Returns:
            ThemeResult: è§£æåçš„ä¸»é¢˜ç»“æœ
        """
        data = self._extract_json(raw_text.replace('[STREAM_END]', '').strip())
        return ThemeResult(**data)


    # ==== å·¥å…·æ–¹æ³• ====

    def _sample_transcript(self, text: str, max_chars: int = 15000) -> str:
        """å‡åŒ€é‡‡æ ·é•¿å­—å¹•"""
        if len(text) <= max_chars:
            return text
        
        lines = text.strip().split('\n')
        num_segments = 10
        lines_per_seg = len(lines) // num_segments
        
        sampled = []
        for i in range(num_segments):
            start = i * lines_per_seg
            end = min(start + lines_per_seg, len(lines))
            sampled.append('\n'.join(lines[start:end]))
        
        return "\n\n[...]\n\n".join(sampled)
    
    def _extract_json(self, text: str) -> dict:
        """ä»æ–‡æœ¬ä¸­æå– JSON"""
        import json
        import re
        
        text = re.sub(r'^```json?\s*', '', text.strip())
        text = re.sub(r'\s*```$', '', text)
        
        start = text.find('{')
        if start == -1:
            return {}
        
        brace_count = 0
        end = start
        for i, c in enumerate(text[start:], start):
            if c == '{': brace_count += 1
            elif c == '}': 
                brace_count -= 1
                if brace_count == 0:
                    end = i + 1
                    break
        
        return json.loads(text[start:end])


# ========= å…¨å±€å•ä¾‹ =========

_llm_service: Optional[LLMService] = None

def get_llm_service() -> LLMService:
    """è·å– LLM æœåŠ¡å•ä¾‹"""
    global _llm_service
    if _llm_service is None:
        _llm_service = LLMService()
    return _llm_service

