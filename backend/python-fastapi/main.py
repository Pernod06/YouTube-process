"""
Python + FastAPI åç«¯ç¤ºä¾‹
å®‰è£…ä¾èµ–: pip install fastapi uvicorn python-multipart
"""

import logging
from logging.handlers import RotatingFileHandler
import os as _os
from pathlib import Path as _Path

# ========== æ—¥å¿—é…ç½® ==========
# è‡ªåŠ¨æ£€æµ‹è¿è¡Œç¯å¢ƒï¼šDocker ä½¿ç”¨ /app/logsï¼Œæœ¬åœ°ä½¿ç”¨é¡¹ç›®ç›®å½•ä¸‹çš„ logs
if _os.path.exists("/app"):
    LOG_DIR = "/app/logs"
else:
    LOG_DIR = str(_Path(__file__).parent.parent.parent / "logs")
_os.makedirs(LOG_DIR, exist_ok=True)

# æ–‡ä»¶æ—¥å¿—å¤„ç†å™¨
_file_handler = RotatingFileHandler(
    f"{LOG_DIR}/app.log",
    maxBytes=50*1024*1024,  # 50MB
    backupCount=5,
    encoding='utf-8'
)
_file_handler.setFormatter(logging.Formatter(
    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
))

# æ§åˆ¶å°æ—¥å¿—å¤„ç†å™¨
_console_handler = logging.StreamHandler()
_console_handler.setFormatter(logging.Formatter(
    '%(asctime)s - %(levelname)s - %(message)s'
))

# é…ç½®æ ¹æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    handlers=[_file_handler, _console_handler]
)

logger = logging.getLogger(__name__)
logger.info("=== åº”ç”¨å¯åŠ¨ï¼Œæ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ ===")
# ==============================

from fastapi import FastAPI, HTTPException, Query, Request, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, StreamingResponse, Response
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import json
import os
from datetime import datetime
from pathlib import Path
import sys

# Supabase é…ç½®
from supabase import create_client, Client

SUPABASE_URL = "https://xxurqudxplxhignlshhy.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Inh4dXJxdWR4cGx4aGlnbmxzaGh5Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjUyNDAxMjEsImV4cCI6MjA4MDgxNjEyMX0.afuHUdv5pDwKrMbEon5Tcy2W2EHTR9ZMlka8jiECGDY"

def get_supabase_client() -> Client:
    """è·å– Supabase å®¢æˆ·ç«¯"""
    return create_client(SUPABASE_URL, SUPABASE_KEY)

def get_cached_video_from_supabase(video_id: str) -> dict | None:
    """ä» Supabase è·å–ç¼“å­˜çš„è§†é¢‘æ•°æ®"""
    try:
        client = get_supabase_client()
        result = client.table("youtube_videos").select("*").eq("video_id", video_id).single().execute()
        if result.data:
            return result.data
        return None
    except Exception as e:
        print(f"[WARN] ä» Supabase è·å–ç¼“å­˜å¤±è´¥: {e}")
        return None

def save_video_to_supabase(video_id: str, video_data: dict, transcript: str = None, chapters: list = None):
    """ä¿å­˜è§†é¢‘æ•°æ®åˆ° Supabase"""
    try:
        client = get_supabase_client()
        record = {
            "video_id": video_id,
            "video_data": video_data,
            "transcript": transcript,
            "chapters": chapters
        }
        client.table("youtube_videos").upsert(record, on_conflict="video_id").execute()
        print(f"[SUCCESS] è§†é¢‘æ•°æ®å·²ä¿å­˜åˆ° Supabase: {video_id}")
    except Exception as e:
        print(f"[WARN] ä¿å­˜åˆ° Supabase å¤±è´¥: {e}")

def record_user_usage(user_id: str, video_id: str, video_title: str = None, action_type: str = "analysis"):
    """è®°å½•ç”¨æˆ·ä½¿ç”¨åˆ†æåŠŸèƒ½"""
    if not user_id:
        print(f"[Usage] åŒ¿åç”¨æˆ·ï¼Œè·³è¿‡ä½¿ç”¨è®°å½•")
        return False
    
    try:
        client = get_supabase_client()
        record = {
            "user_id": user_id,
            "video_id": video_id,
            "video_title": video_title,
            "action_type": action_type
        }
        client.table("user_usage").insert(record).execute()
        print(f"[Usage] âœ… å·²è®°å½•ç”¨æˆ· {user_id[:8]}... åˆ†æè§†é¢‘: {video_id}")
        return True
    except Exception as e:
        print(f"[Usage] âš ï¸ è®°å½•ä½¿ç”¨å¤±è´¥: {e}")
        return False

# æ·»åŠ ä»¥ä¸‹ä»£ç æ¥åŠ è½½ .env æ–‡ä»¶
try:
    from dotenv import load_dotenv
    env_path = Path(__file__).parent.parent.parent / '.env'
    load_dotenv(dotenv_path=env_path)
    print(f"[App] .env æ–‡ä»¶å·²åŠ è½½")
except ImportError:
    print("[App] python-dotenv æœªå®‰è£…")

# å¯¼å…¥è¾…åŠ©æ¨¡å—
from pdf_generator import generate_video_pdf
from video_frame_extractor import extract_frame_at_timestamp, extract_youtube_chapters, extract_multiple_frames

# å¯¼å…¥ LangChain LLM æœåŠ¡
from llm_server import get_llm_service

# å¯¼å…¥ YouTube æœç´¢æœåŠ¡ (SerpAPI)
from youtube_search_service import (
    get_youtube_search_service,
    SearchYouTubeParams,
    YouTubeSearchError
)

# å¯¼å…¥ Chat è·¯ç”±
from chat import router as chat_router

app = FastAPI(
    title="è§†é¢‘å†…å®¹å¹³å° API",
    description="åŠ¨æ€è§†é¢‘å†…å®¹ç®¡ç†ç³»ç»Ÿ",
    version="1.0.0"
)

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ³¨å†Œ Chat è·¯ç”±
app.include_router(chat_router)

# é…ç½®è·¯å¾„
BASE_DIR = Path(__file__).parent.parent.parent
DATA_DIR = BASE_DIR / 'data'
STATIC_DIR = BASE_DIR

# å†…å­˜å­˜å‚¨
comments_db = {}
progress_db = {}


# Pydantic æ¨¡å‹
class Comment(BaseModel):
    comment: str
    author: Optional[str] = "Anonymous"


class CommentResponse(BaseModel):
    id: str
    author: str
    text: str
    timestamp: str


class Progress(BaseModel):
    timestamp: float


class ProgressResponse(BaseModel):
    timestamp: float
    updatedAt: str


class SearchResult(BaseModel):
    videoId: str
    title: str
    thumbnail: str
    url: str
    duration: Optional[str] = None  # æ ¼å¼åŒ–æ—¶é•¿ (å¦‚ "1:02:03")
    channel: Optional[str] = None  # é¢‘é“åç§°
    views: Optional[int] = None  # è§‚çœ‹æ¬¡æ•°
    publishedDate: Optional[str] = None  # å‘å¸ƒæ—¥æœŸ


class SearchResponse(BaseModel):
    results: List[SearchResult]
    total: int


class GenerateThemesRequest(BaseModel):
    video_id: str
    stream: bool = False  # æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º


class VideoFramesRequest(BaseModel):
    timestamps: List[int]


class ProcessVideoRequest(BaseModel):
    url: str
    language: str = "en"  # é»˜è®¤è‹±è¯­ï¼Œæ”¯æŒ: zh, en, ja, ko, es, fr, de, pt, ru, ar
    user_id: Optional[str] = None  # ç”¨æˆ·IDï¼ˆå¯é€‰ï¼Œç”¨äºè®°å½•ä½¿ç”¨æ¬¡æ•°ï¼‰


def load_video_data():
    """åŠ è½½è§†é¢‘æ•°æ®"""
    data_path = DATA_DIR / 'video-data.json'
    with open(data_path, 'r', encoding='utf-8') as f:
        return json.load(f)


@app.get("/api/videos/{video_id}")
async def get_video(video_id: str, language: str = None):
    """è·å–è§†é¢‘æ•°æ®ï¼Œæ”¯æŒç¿»è¯‘ä¸ºç›®æ ‡è¯­è¨€"""
    try:
        # ä» Supabase è·å–è§†é¢‘æ•°æ®
        cached_record = get_cached_video_from_supabase(video_id)
        
        if not cached_record or not cached_record.get('video_data'):
            raise HTTPException(status_code=404, detail=f"è§†é¢‘æ•°æ®ä¸å­˜åœ¨: {video_id}")
        
        video_data = cached_record['video_data']
        
        # å¦‚æœæŒ‡å®šäº†éè‹±æ–‡è¯­è¨€ï¼Œç¿»è¯‘æ•°æ®
        if language and language != 'en':
            print(f"[INFO] ç¿»è¯‘è§†é¢‘æ•°æ®ä¸º {language}...")
            video_data = translate_cached_data(video_data, language)
        
        return video_data
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/transcript/{video_id}")
async def get_transcript(video_id: str):
    """è·å–è§†é¢‘å­—å¹•"""
    try:
        # ä» Supabase è·å–å­—å¹•
        cached_record = get_cached_video_from_supabase(video_id)
        
        if not cached_record or not cached_record.get('transcript'):
            raise HTTPException(status_code=404, detail=f"å­—å¹•ä¸å­˜åœ¨: {video_id}")
        
        content = cached_record['transcript']
        return Response(content=content, media_type="text/plain; charset=utf-8")
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è¯»å–å­—å¹•å¤±è´¥: {str(e)}")


@app.get("/api/videos")
async def get_videos():
    """è·å–è§†é¢‘åˆ—è¡¨ï¼ˆä» Supabaseï¼‰"""
    try:
        client = get_supabase_client()
        result = client.table("youtube_videos").select("video_id, video_data, created_at").order("created_at", desc=True).execute()
        
        videos = []
        for record in result.data:
            video_data = record.get('video_data', {})
            video_info = video_data.get('videoInfo', {})
            videos.append({
                "videoId": record['video_id'],
                "title": video_info.get('title', f"Video {record['video_id']}"),
                "description": video_info.get('description', ''),
                "thumbnail": video_info.get('thumbnail', f"https://img.youtube.com/vi/{record['video_id']}/maxresdefault.jpg"),
                "summary": video_info.get('summary', ''),
                "createdAt": record.get('created_at', '')
            })
        return videos
    except Exception as e:
        print(f"[ERROR] è·å–è§†é¢‘åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/videos/{video_id}/comments")
async def get_comments(video_id: str, maxResults: Optional[int] = Query(20)):
    """è·å–YouTubeè¯„è®º"""
    try:
        # å°è¯•å¯¼å…¥ youtube_client
        import traceback
        sys.path.append(str(BASE_DIR))
        
        print(f"[INFO] æ­£åœ¨è·å–è§†é¢‘ {video_id} çš„è¯„è®º...")
        
        from youtube_client import YouTubeClient
        
        # åˆ›å»º YouTube å®¢æˆ·ç«¯
        print("[INFO] æ­£åœ¨åˆå§‹åŒ– YouTube å®¢æˆ·ç«¯...")
        client = YouTubeClient()
        
        # è·å–è¯„è®ºæ•°é‡å‚æ•°ï¼ˆé»˜è®¤20æ¡ï¼‰
        max_results = min(maxResults, 30)  # é™åˆ¶æœ€å¤§100æ¡
        
        print(f"[INFO] æ­£åœ¨è°ƒç”¨ YouTube API è·å– {max_results} æ¡è¯„è®º...")
        # è°ƒç”¨ YouTube API è·å–è¯„è®º
        print(f"[INFO] è§†é¢‘ID: {video_id}")
        comments = client.get_video_comments(video_id, max_results=max_results)
        
        if comments:
            print(f"[SUCCESS] æˆåŠŸè·å– {len(comments)} æ¡è¯„è®º")
            return {
                'success': True,
                'videoId': video_id,
                'comments': comments,
                'total': len(comments)
            }
            
        else:
            # å¦‚æœè·å–å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
            print("[WARNING] æœªè·å–åˆ°è¯„è®º")
            return {
                'success': True,
                'videoId': video_id,
                'comments': [],
                'total': 0,
                'message': 'è¯¥è§†é¢‘æ²¡æœ‰è¯„è®ºæˆ–è¯„è®ºå·²å…³é—­'
            }
    except ImportError as e:
        # å¦‚æœæ— æ³•å¯¼å…¥ youtube_clientï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
        print(f"[ERROR] å¯¼å…¥é”™è¯¯: {str(e)}")
        traceback.print_exc()
        return {
            'success': False,
            'videoId': video_id,
            'comments': [],
            'total': 0,
            'error': str(e),
            'message': 'YouTube API å®¢æˆ·ç«¯å¯¼å…¥å¤±è´¥'
        }
    except ValueError as e:
        # YouTube API å¯†é’¥æœªé…ç½®
        print(f"[ERROR] é…ç½®é”™è¯¯: {str(e)}")
        return {
            'success': False,
            'videoId': video_id,
            'comments': [],
            'total': 0,
            'error': str(e),
            'message': 'YouTube API å¯†é’¥æœªé…ç½®æˆ–æ— æ•ˆï¼Œè¯·æ£€æŸ¥ config.py'
        }
    except Exception as e:
        print(f"[ERROR] æœªçŸ¥é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail={
                'success': False,
                'videoId': video_id,
                'error': str(e),
                'error_type': type(e).__name__,
                'message': 'è·å–è¯„è®ºå¤±è´¥ï¼Œè¯·æŸ¥çœ‹åç«¯æ—¥å¿—'
            }
        )


@app.post("/api/videos/{video_id}/comments", response_model=CommentResponse, status_code=201)
async def post_comment(video_id: str, comment_data: Comment):
    """å‘å¸ƒè¯„è®º"""
    if video_id not in comments_db:
        comments_db[video_id] = []
    
    new_comment = {
        "id": str(int(datetime.now().timestamp() * 1000)),
        "author": comment_data.author,
        "text": comment_data.comment,
        "timestamp": datetime.now().isoformat()
    }
    
    comments_db[video_id].append(new_comment)
    return new_comment


@app.get("/api/videos/{video_id}/progress")
async def get_progress(video_id: str):
    """è·å–æ’­æ”¾è¿›åº¦"""
    user_progress = progress_db.get(video_id, {'timestamp': 0})
    return user_progress


@app.put("/api/videos/{video_id}/progress")
async def update_progress(video_id: str, progress_data: Progress):
    """æ›´æ–°æ’­æ”¾è¿›åº¦"""
    progress_db[video_id] = {
        "timestamp": progress_data.timestamp,
        "updatedAt": datetime.now().isoformat()
    }
    
    return {
        "success": True,
        "progress": progress_db[video_id]
    }


@app.get("/api/search", response_model=SearchResponse)
async def search(
    query: str = Query(..., description="æœç´¢å…³é”®è¯"), 
    limit: int = Query(10, description="è¿”å›ç»“æœæ•°é‡é™åˆ¶"),
    order: str = Query("viewCount", description="æ’åºæ–¹å¼: relevance, date, viewCount, rating, title"),
    duration: str = Query("long", description="è§†é¢‘æ—¶é•¿: any, short(<4min), medium(4-20min), long(>20min)"),
    time_filter: Optional[str] = Query(None, description="æ—¶é—´è¿‡æ»¤: hour, today, week, month, year")
):
    """é€šè¿‡ YouTube API æœç´¢è§†é¢‘"""
    try:
        print(f"[INFO] æœç´¢ YouTube: {query}, limit={limit}, order={order}, duration={duration}, time_filter={time_filter}")
        
        # å¯¼å…¥ YouTubeClient
        sys.path.append(str(BASE_DIR))
        from youtube_client import YouTubeClient
        
        # åˆ›å»ºå®¢æˆ·ç«¯å¹¶æœç´¢
        client = YouTubeClient()
        youtube_results = client.search_videos(query, max_results=limit, order=order, 
                                               published_after=time_filter, duration=duration)
        
        # è½¬æ¢ä¸ºå‰ç«¯æœŸæœ›çš„æ ¼å¼
        results = []
        for video in youtube_results:
            video_id = video.get('video_id', '')
            thumbnails = video.get('thumbnails', {})
            thumbnail = thumbnails.get('high') or thumbnails.get('medium') or thumbnails.get('default') or f'https://img.youtube.com/vi/{video_id}/maxresdefault.jpg'
            
            # æ ¼å¼åŒ–å‘å¸ƒæ—¥æœŸ
            published_at = video.get('published_at', '')
            published_date = None
            if published_at:
                try:
                    from datetime import datetime
                    pub_dt = datetime.fromisoformat(published_at.replace('Z', '+00:00'))
                    now = datetime.now(pub_dt.tzinfo)
                    diff = now - pub_dt
                    if diff.days == 0:
                        published_date = "Today"
                    elif diff.days == 1:
                        published_date = "Yesterday"
                    elif diff.days < 7:
                        published_date = f"{diff.days} days ago"
                    elif diff.days < 30:
                        weeks = diff.days // 7
                        published_date = f"{weeks} week{'s' if weeks > 1 else ''} ago"
                    elif diff.days < 365:
                        months = diff.days // 30
                        published_date = f"{months} month{'s' if months > 1 else ''} ago"
                    else:
                        years = diff.days // 365
                        published_date = f"{years} year{'s' if years > 1 else ''} ago"
                except:
                    published_date = published_at[:10] if published_at else None
            
            results.append({
                "videoId": video_id,
                "title": video.get('title', ''),
                "thumbnail": thumbnail,
                "url": f"https://www.youtube.com/watch?v={video_id}",
                "duration": video.get('duration_formatted', ''),  # æ ¼å¼åŒ–æ—¶é•¿
                "channel": video.get('channel_title', ''),  # é¢‘é“åç§°
                "views": video.get('view_count', 0),  # è§‚çœ‹æ¬¡æ•°
                "publishedDate": published_date  # æ ¼å¼åŒ–å‘å¸ƒæ—¥æœŸ
            })
        
        print(f"[SUCCESS] æ‰¾åˆ° {len(results)} ä¸ªè§†é¢‘")
        
        return {
            "results": results,
            "total": len(results)
        }
    except ValueError as e:
        # YouTube API å¯†é’¥æœªé…ç½®
        print(f"[ERROR] YouTube API é…ç½®é”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=f"YouTube API é…ç½®é”™è¯¯: {str(e)}")
    except Exception as e:
        print(f"[ERROR] æœç´¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "ok",
        "timestamp": datetime.now().isoformat(),
        "version": "1.0.0"
    }


# ==================== SerpAPI YouTube æœç´¢ ====================

class SerpAPISearchRequest(BaseModel):
    """SerpAPI YouTube æœç´¢è¯·æ±‚æ¨¡å‹"""
    search_query: str
    gl: Optional[str] = None  # å›½å®¶/åœ°åŒºä»£ç  (å¦‚ "us", "cn")
    hl: Optional[str] = None  # è¯­è¨€ä»£ç  (å¦‚ "en", "zh-CN")
    duration: Optional[str] = None  # è§†é¢‘æ—¶é•¿: any, short(<20min), medium(20min-1hour), long(>1hour)
    limit: Optional[int] = None  # è¿”å›ç»“æœæ•°é‡é™åˆ¶


class SerpAPIVideoResult(BaseModel):
    """SerpAPI è§†é¢‘ç»“æœæ¨¡å‹"""
    position: Optional[int] = None
    title: str
    videoId: str
    link: str
    thumbnail: Optional[str] = None
    channel: Optional[str] = None
    channelLink: Optional[str] = None
    publishedDate: Optional[str] = None
    views: Optional[int] = None
    length: Optional[str] = None
    description: Optional[str] = None


class SerpAPISearchResponse(BaseModel):
    """SerpAPI æœç´¢å“åº”æ¨¡å‹"""
    success: bool
    results: List[SerpAPIVideoResult]
    total: int
    cached: bool = False


@app.post("/api/search-youtube", response_model=SerpAPISearchResponse)
async def search_youtube_serpapi(request: SerpAPISearchRequest):
    """
    ä½¿ç”¨ SerpAPI æœç´¢ YouTube è§†é¢‘
    
    ä¸ NestJS ç‰ˆæœ¬ SearchYouTubeService åŠŸèƒ½ä¸€è‡´:
    - æ”¯æŒ search_query æœç´¢å…³é”®è¯
    - 10åˆ†é’Ÿç¼“å­˜æœºåˆ¶
    - è¿”å› video_results åˆ—è¡¨
    
    Request Body:
        {
            "search_query": "æœç´¢å…³é”®è¯",
            "gl": "us",  // å¯é€‰ï¼Œå›½å®¶/åœ°åŒºä»£ç 
            "hl": "en"   // å¯é€‰ï¼Œè¯­è¨€ä»£ç 
        }
    
    Response:
        {
            "success": true,
            "results": [...],
            "total": 10,
            "cached": false
        }
    """
    try:
        print(f"[INFO] SerpAPI YouTube æœç´¢: {request.search_query}, duration={request.duration}, limit={request.limit}")
        
        # è·å–æœç´¢æœåŠ¡
        service = get_youtube_search_service()
        
        # æ„å»ºæœç´¢å‚æ•°
        params = SearchYouTubeParams(
            search_query=request.search_query,
            engine="youtube",
            gl=request.gl,
            hl=request.hl,
            duration=request.duration,
            limit=request.limit
        )
        
        # æ‰§è¡Œæœç´¢
        response = await service.search_youtube(params)
        
        # è½¬æ¢ä¸ºå‰ç«¯å‹å¥½çš„æ ¼å¼
        results = []
        for video in response.video_results:
            # æå–è§†é¢‘ IDï¼ˆä»é“¾æ¥ä¸­ï¼‰
            video_id = ""
            link = video.get('link', '')
            if 'watch?v=' in link:
                video_id = link.split('watch?v=')[1].split('&')[0]
            
            # æå–ç¼©ç•¥å›¾
            thumbnail = ""
            thumb_data = video.get('thumbnail', {})
            if isinstance(thumb_data, dict):
                thumbnail = thumb_data.get('static', '') or thumb_data.get('rich', '')
            elif isinstance(thumb_data, str):
                thumbnail = thumb_data
            
            # æå–é¢‘é“ä¿¡æ¯
            channel_data = video.get('channel', {})
            channel_name = ""
            channel_link = ""
            if isinstance(channel_data, dict):
                channel_name = channel_data.get('name', '')
                channel_link = channel_data.get('link', '')
            elif isinstance(channel_data, str):
                channel_name = channel_data
            
            results.append(SerpAPIVideoResult(
                position=video.get('position'),
                title=video.get('title', ''),
                videoId=video_id,
                link=link,
                thumbnail=thumbnail,
                channel=channel_name,
                channelLink=channel_link,
                publishedDate=video.get('published_date'),
                views=video.get('views'),
                length=video.get('length'),
                description=video.get('description')
            ))
        
        print(f"[SUCCESS] SerpAPI æœç´¢æˆåŠŸï¼Œæ‰¾åˆ° {len(results)} ä¸ªè§†é¢‘")
        
        return SerpAPISearchResponse(
            success=True,
            results=results,
            total=len(results),
            cached=False  # ç¼“å­˜çŠ¶æ€ç”±æœåŠ¡å†…éƒ¨å¤„ç†
        )
        
    except YouTubeSearchError as e:
        print(f"[ERROR] SerpAPI æœç´¢å¤±è´¥: {e.message}")
        raise HTTPException(
            status_code=500,
            detail={
                'success': False,
                'error': e.message,
                'message': 'YouTube æœç´¢å¤±è´¥'
            }
        )
    except Exception as e:
        print(f"[ERROR] SerpAPI æœç´¢å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail={
                'success': False,
                'error': str(e),
                'message': 'YouTube æœç´¢å¤±è´¥'
            }
        )


@app.get("/api/search-youtube/cache-stats")
async def get_youtube_search_cache_stats():
    """è·å– YouTube æœç´¢ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    service = get_youtube_search_service()
    return {
        'success': True,
        'stats': service.get_cache_stats()
    }


@app.delete("/api/search-youtube/cache")
async def clear_youtube_search_cache():
    """æ¸…ç©º YouTube æœç´¢ç¼“å­˜"""
    service = get_youtube_search_service()
    service.clear_cache()
    return {
        'success': True,
        'message': 'ç¼“å­˜å·²æ¸…ç©º'
    }


# Chat è·¯ç”±å·²è¿ç§»åˆ° chat.py


@app.post("/api/generate-themes/{video_id}")
async def generate_themes(
    video_id: str, 
    stream: bool = Query(False, description="æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º"),
    language: str = Query("en", description="è¾“å‡ºè¯­è¨€: en, zh, ja, ko, es, fr, de")
):
    """
    æ ¹æ®è§†é¢‘åˆ†ææ•°æ®ç”Ÿæˆ 2-5 ä¸ªä¸»é¢˜
    
    Args:
        video_id: YouTube è§†é¢‘ ID
        stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡ºï¼ˆé»˜è®¤ Falseï¼‰
        language: è¾“å‡ºè¯­è¨€ä»£ç ï¼ˆé»˜è®¤è‹±è¯­ï¼‰
    
    Returns:
        - éæµå¼ï¼šç›´æ¥è¿”å›å®Œæ•´çš„ä¸»é¢˜ JSON
        - æµå¼ï¼šè¿”å› SSE æµ
    """
    try:
        print(f"[INFO] ç”Ÿæˆä¸»é¢˜ - è§†é¢‘ID: {video_id}, stream: {stream}, language: {language}")
        
        # ä» Supabase è·å–è§†é¢‘æ•°æ®
        cached_record = get_cached_video_from_supabase(video_id)
        
        if not cached_record or not cached_record.get('video_data'):
            raise HTTPException(
                status_code=404,
                detail={'success': False, 'error': 'Video data not found', 'message': f'è§†é¢‘æ•°æ®ä¸å­˜åœ¨: {video_id}'}
            )
        
        video_data = cached_record['video_data']
        
        if not video_data.get('sections'):
            raise HTTPException(
                status_code=400,
                detail={'success': False, 'error': 'No sections found', 'message': 'è§†é¢‘æ•°æ®ä¸­æ²¡æœ‰ç« èŠ‚ä¿¡æ¯'}
            )
        
        llm_service = get_llm_service()
        
        if stream:
            # æµå¼è¾“å‡º
            async def generate_stream():
                try:
                    full_response = ""
                    async for chunk in llm_service.generate_themes_stream(video_data, language):
                        if chunk == "\n[STREAM_END]":
                            continue
                        full_response += chunk
                        yield f"data: {chunk}\n\n"
                    
                    # è§£ææœ€ç»ˆç»“æœ
                    try:
                        theme_result = llm_service.parse_themes_result(full_response)
                        yield f'data: [DONE] {json.dumps(theme_result.model_dump(), ensure_ascii=False)}\n\n'
                    except Exception as parse_error:
                        print(f"[WARN] ä¸»é¢˜è§£æå¤±è´¥: {parse_error}")
                        yield f'data: [DONE] {full_response}\n\n'
                        
                except Exception as e:
                    print(f"[ERROR] æµå¼ç”Ÿæˆä¸»é¢˜å¤±è´¥: {e}")
                    yield f'data: [ERROR] {str(e)}\n\n'
            
            return StreamingResponse(
                generate_stream(),
                media_type="text/event-stream",
                headers={
                    "Cache-Control": "no-cache",
                    "Connection": "keep-alive",
                    "X-Accel-Buffering": "no"
                }
            )
        else:
            # éæµå¼è¾“å‡º
            theme_result = llm_service.generate_themes(video_data, language)
            
            print(f"[SUCCESS] ç”Ÿæˆäº† {len(theme_result.themes)} ä¸ªä¸»é¢˜")
            
            return {
                'success': True,
                'videoId': video_id,
                'themes': theme_result.model_dump()['themes'],
                'total': len(theme_result.themes)
            }
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] ç”Ÿæˆä¸»é¢˜å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail={'success': False, 'error': str(e), 'message': 'ç”Ÿæˆä¸»é¢˜å¤±è´¥'}
        )


@app.post("/api/generate-themes")
async def generate_themes_from_json(request: Request):
    """
    æ ¹æ®ä¼ å…¥çš„è§†é¢‘ JSON æ•°æ®ç›´æ¥ç”Ÿæˆä¸»é¢˜ï¼ˆæ— éœ€è§†é¢‘IDï¼‰
    
    Request Body:
        {
            "video_data": { ... è§†é¢‘åˆ†æ JSON ... },
            "stream": false
        }
    """
    try:
        body = await request.json()
        video_data = body.get('video_data')
        stream = body.get('stream', False)
        
        if not video_data:
            raise HTTPException(status_code=400, detail={'success': False, 'message': 'ç¼ºå°‘ video_data'})
        
        if not video_data.get('sections'):
            raise HTTPException(status_code=400, detail={'success': False, 'message': 'è§†é¢‘æ•°æ®ä¸­æ²¡æœ‰ sections'})
        
        print(f"[INFO] ä» JSON ç”Ÿæˆä¸»é¢˜, sections æ•°é‡: {len(video_data.get('sections', []))}")
        
        llm_service = get_llm_service()
        
        if stream:
            async def generate_stream():
                try:
                    full_response = ""
                    async for chunk in llm_service.generate_themes_stream(video_data):
                        if chunk == "\n[STREAM_END]":
                            continue
                        full_response += chunk
                        yield f"data: {chunk}\n\n"
                    
                    try:
                        theme_result = llm_service.parse_themes_result(full_response)
                        yield f'data: [DONE] {json.dumps(theme_result.model_dump(), ensure_ascii=False)}\n\n'
                    except:
                        yield f'data: [DONE] {full_response}\n\n'
                except Exception as e:
                    yield f'data: [ERROR] {str(e)}\n\n'
            
            return StreamingResponse(
                generate_stream(),
                media_type="text/event-stream",
                headers={"Cache-Control": "no-cache", "Connection": "keep-alive", "X-Accel-Buffering": "no"}
            )
        else:
            theme_result = llm_service.generate_themes(video_data)
            return {
                'success': True,
                'themes': theme_result.model_dump()['themes'],
                'total': len(theme_result.themes)
            }
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] ç”Ÿæˆä¸»é¢˜å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail={'success': False, 'error': str(e)})


class PDFExportRequest(BaseModel):
    notes: list = []
    videoTitle: str = ""

@app.post("/api/generate-pdf/{video_id}")
async def generate_pdf_post(video_id: str, request: PDFExportRequest = None):
    """
    ç”Ÿæˆè§†é¢‘æ•°æ®çš„ PDF æ–‡æ¡£ï¼ˆæ”¯æŒåŒ…å«ç¬”è®°ï¼‰
    
    Args:
        video_id: YouTube è§†é¢‘ ID
        request: å¯é€‰çš„è¯·æ±‚ä½“ï¼ŒåŒ…å« notes å’Œ videoTitle
    """
    return await _generate_pdf_internal(video_id, request)

@app.get("/api/generate-pdf/{video_id}")
async def generate_pdf(video_id: str):
    """
    ç”Ÿæˆè§†é¢‘æ•°æ®çš„ PDF æ–‡æ¡£ï¼ˆGET æ–¹å¼ï¼Œå‘åå…¼å®¹ï¼‰
    
    Args:
        video_id: YouTube è§†é¢‘ ID
    """
    return await _generate_pdf_internal(video_id, None)

async def _generate_pdf_internal(video_id: str, request: PDFExportRequest = None):
    """
    å†…éƒ¨ PDF ç”Ÿæˆå‡½æ•°
    """
    try:
        print(f'[INFO] å¼€å§‹ç”Ÿæˆ PDF for video {video_id}...')
        
        # ä» Supabase è·å–è§†é¢‘æ•°æ®
        cached_record = get_cached_video_from_supabase(video_id)
        
        if not cached_record or not cached_record.get('video_data'):
            raise HTTPException(
                status_code=404,
                detail={
                    'success': False,
                    'error': 'Video data not found',
                    'message': f'è§†é¢‘æ•°æ®ä¸å­˜åœ¨: {video_id}'
                }
            )
        
        video_data = cached_record['video_data']
        
        # æå–ç¬”è®°æ•°æ®
        notes = request.notes if request else []
        
        # ç”Ÿæˆ PDFï¼ˆåœ¨å†…å­˜ä¸­ï¼‰ï¼Œä¼ å…¥ç¬”è®°
        pdf_buffer = generate_video_pdf(video_data, output_path=None, notes=notes)
        
        # ç”Ÿæˆæ–‡ä»¶å
        video_title = video_data.get('videoInfo', {}).get('title', 'video')
        # æ¸…ç†æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦ï¼ˆåªä¿ç•™ ASCII å­—ç¬¦ï¼‰
        safe_title = "".join(c for c in video_title if c.isascii() and (c.isalnum() or c in (' ', '-', '_'))).strip()
        safe_title = safe_title[:50] if safe_title else video_id  # å¦‚æœä¸ºç©ºåˆ™ä½¿ç”¨ video_id
        filename = f"{safe_title}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
        
        # å¯¹æ–‡ä»¶åè¿›è¡Œ URL ç¼–ç ä»¥æ”¯æŒç‰¹æ®Šå­—ç¬¦
        from urllib.parse import quote
        encoded_filename = quote(filename)
        
        print(f'[SUCCESS] PDF ç”ŸæˆæˆåŠŸ: {filename}')
        
        # è¯»å– buffer å†…å®¹
        pdf_content = pdf_buffer.getvalue()
        
        # ä½¿ç”¨ Response è€Œä¸æ˜¯ StreamingResponseï¼Œç¡®ä¿å®Œæ•´ä¼ è¾“
        # ä½¿ç”¨ RFC 5987 æ ¼å¼æ”¯æŒ UTF-8 æ–‡ä»¶å
        return Response(
            content=pdf_content,
            media_type='application/pdf',
            headers={
                'Content-Disposition': f"attachment; filename=\"{video_id}.pdf\"; filename*=UTF-8''{encoded_filename}",
                'Content-Length': str(len(pdf_content))
            }
        )
        
    except Exception as e:
        print(f'[ERROR] PDF ç”Ÿæˆå¤±è´¥: {str(e)}')
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail={
                'success': False,
                'error': str(e),
                'message': 'PDF ç”Ÿæˆå¤±è´¥'
            }
        )


@app.get("/api/video-frame/{video_id}")
async def get_video_frame(video_id: str, timestamp: int = Query(0)):
    """
    è·å–è§†é¢‘æŒ‡å®šæ—¶é—´æˆ³çš„å¸§å›¾ç‰‡
    
    Query Parameters:
        - timestamp: æ—¶é—´æˆ³ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ä¸º 0
    
    Example:
        GET /api/video-frame/EF8C4v7JIbA?timestamp=1794
    """
    try:
        print(f"[INFO] æ”¶åˆ°å¸§æå–è¯·æ±‚ - è§†é¢‘ID: {video_id}, æ—¶é—´æˆ³: {timestamp}")
        
        # æå–å¸§
        frame_path = extract_frame_at_timestamp(video_id, timestamp)
        
        # è¿”å›å›¾ç‰‡æ–‡ä»¶
        return FileResponse(
            frame_path,
            media_type='image/jpeg',
            filename=f"frame_{video_id}_{timestamp}.jpg"
        )
        
    except Exception as e:
        print(f"[ERROR] å¸§æå–å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        
        raise HTTPException(
            status_code=500,
            detail={
                'success': False,
                'error': str(e),
                'message': 'æ— æ³•æå–è§†é¢‘å¸§'
            }
        )


@app.get("/api/video-info/{video_id}")
async def get_video_info(video_id: str):
    """è·å– YouTube è§†é¢‘ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€æè¿°ç­‰ï¼‰"""
    try:
        print(f"[INFO] è·å–è§†é¢‘ä¿¡æ¯ - è§†é¢‘ID: {video_id}")
        
        sys.path.append(str(BASE_DIR))
        from youtube_get_video_information import get_video_information
        
        # è·å–è§†é¢‘ä¿¡æ¯
        video_info = get_video_information(video_id)
        
        if not video_info:
            raise HTTPException(status_code=404, detail={'success': False, 'message': 'æ— æ³•è·å–è§†é¢‘ä¿¡æ¯'})
        
        print(f"[SUCCESS] è§†é¢‘ä¿¡æ¯è·å–æˆåŠŸ")
        
        return {
            'success': True,
            'videoId': video_id,
            'title': video_info.get('title', ''),
            'description': video_info.get('description', ''),
            'channelTitle': video_info.get('channel_title', ''),
            'publishedAt': video_info.get('published_at', ''),
            'duration': video_info.get('duration', ''),
            'viewCount': video_info.get('view_count', 0),
            'likeCount': video_info.get('like_count', 0),
            'thumbnail': video_info.get('thumbnails', {}).get('maxres', '')
        }
        
    except Exception as e:
        print(f"[ERROR] è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail={'success': False, 'error': str(e)})


@app.get("/api/video-chapters/{video_id}")
async def get_video_chapters(video_id: str):
    """è·å–è§†é¢‘ç« èŠ‚åˆ—è¡¨ï¼ˆç›´æ¥è°ƒç”¨ç°æœ‰å‡½æ•°ï¼‰"""
    try:
        video_title, chapters = extract_youtube_chapters(video_id)
        
        if not chapters:
            raise HTTPException(status_code=404, detail={'success': False, 'message': 'æœªæ‰¾åˆ°ç« èŠ‚'})
        
        return {'success': True, 'chapters': chapters, 'total': len(chapters)}
    except Exception as e:
        raise HTTPException(status_code=500, detail={'success': False, 'error': str(e)})


@app.post("/api/video-frames/{video_id}")
async def get_video_frames_batch(video_id: str, request: VideoFramesRequest):
    """
    æ‰¹é‡è·å–è§†é¢‘å¤šä¸ªæ—¶é—´æˆ³çš„å¸§å›¾ç‰‡
    
    Request Body:
        {
            "timestamps": [10, 30, 60, 120, 180]  // æ—¶é—´æˆ³æ•°ç»„ï¼ˆç§’ï¼‰
        }
    
    Response:
        {
            "success": true,
            "videoId": "xxx",
            "frames": [
                {
                    "timestamp": 10,
                    "success": true,
                    "url": "/api/video-frame/xxx?timestamp=10"
                },
                ...
            ]
        }
    
    Example:
        POST /api/video-frames/EF8C4v7JIbA
        Body: {"timestamps": [10, 30, 60]}
    """
    timestamps = request.timestamps
    
    try:
        print(f"[INFO] æ”¶åˆ°æ‰¹é‡å¸§æå–è¯·æ±‚ - è§†é¢‘ID: {video_id}, æ—¶é—´æˆ³æ•°é‡: {len(timestamps)}")
        
        # æå–å¤šä¸ªå¸§
        results = extract_multiple_frames(video_id, timestamps)
        
        # è½¬æ¢ç»“æœæ ¼å¼ï¼Œæ·»åŠ  URL
        frames = []
        for result in results:
            if result['success']:
                frames.append({
                    'timestamp': result['timestamp'],
                    'success': True,
                    'url': f"/api/video-frame/{video_id}?timestamp={result['timestamp']}"
                })
            else:
                frames.append({
                    'timestamp': result['timestamp'],
                    'success': False,
                    'error': result.get('error', 'Unknown error')
                })
        
        success_count = sum(1 for f in frames if f['success'])
        print(f"[SUCCESS] æ‰¹é‡å¸§æå–å®Œæˆ - æˆåŠŸ: {success_count}/{len(timestamps)}")
        
        return {
            'success': True,
            'videoId': video_id,
            'frames': frames,
            'total': len(frames),
            'successCount': success_count
        }
        
    except Exception as e:
        print(f"[ERROR] æ‰¹é‡å¸§æå–å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        
        raise HTTPException(
            status_code=500,
            detail={
                'success': False,
                'error': str(e),
                'message': 'æ‰¹é‡æå–è§†é¢‘å¸§å¤±è´¥'
            }
        )



@app.post('/api/process-video')
async def process_video(request_data: ProcessVideoRequest):
    """
    å¤„ç†å‰ç«¯ä¼ æ¥çš„ YouTube è§†é¢‘ URLï¼š
    - æå–è§†é¢‘ ID
    - é¦–å…ˆæ£€æŸ¥ data ç›®å½•æ˜¯å¦æœ‰ç¼“å­˜æ•°æ®ï¼Œæœ‰åˆ™ç›´æ¥è¿”å›
    - æ— ç¼“å­˜åˆ™é€šè¿‡ get_full_transcript è·å–å®Œæ•´å­—å¹•å’Œè§†é¢‘ä¿¡æ¯
    - å°†å­—å¹•å†™å…¥ data/transcript_{video_id}.txt
    - è¿”å›åŸºæœ¬å¤„ç†çŠ¶æ€ç»™å‰ç«¯
    """
    url = request_data.url
    language = request_data.language

    if not url:
        raise HTTPException(status_code=400, detail='URL is required')

    try:
        print(f"[INFO] å¼€å§‹å¤„ç†è§†é¢‘: {url}")

        import sys
        import json
        sys.path.append(str(BASE_DIR))

        from get_full_transcript_ytdlp import get_full_transcript, display_full_transcript
        from youtube_client import YouTubeClient

        # æå–è§†é¢‘ ID
        video_id = YouTubeClient.extract_video_id(url)
        if not video_id:
            raise HTTPException(status_code=400, detail='æ— æ³•ä»URLæå–è§†é¢‘ID')

        # ä» Supabase æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜æ•°æ®
        cached_record = get_cached_video_from_supabase(video_id)
        if cached_record and cached_record.get('video_data'):
            print(f"[INFO] ä» Supabase å‘ç°ç¼“å­˜æ•°æ®: {video_id}")
            try:
                cached_data = cached_record['video_data']
                
                # ç¿»è¯‘ç¼“å­˜æ•°æ®ä¸ºç›®æ ‡è¯­è¨€
                if language and language != 'en':
                    print(f"[INFO] æ­£åœ¨å°†ç¼“å­˜æ•°æ®ç¿»è¯‘ä¸º {language}...")
                    cached_data = translate_cached_data(cached_data, language)
                
                # è·å–ç¼“å­˜ä¸­çš„è§†é¢‘æ ‡é¢˜
                video_title = cached_data.get('videoInfo', {}).get('title', '')
                
                print(f"[SUCCESS] ä½¿ç”¨ Supabase ç¼“å­˜æ•°æ®è¿”å›ï¼Œè§†é¢‘æ ‡é¢˜: {video_title}")
                return {
                    'success': True,
                    'videoId': video_id,
                    'title': video_title,
                    'transcriptLength': len(cached_record.get('transcript', '') or ''),
                    'dataFile': f"video-data-{video_id}.json",
                    'chapters': cached_data.get('chapters', []),
                    'sections': cached_data.get('sections', []),
                    'videoInfo': cached_data.get('videoInfo', {}),
                    'message': 'è§†é¢‘å¤„ç†æˆåŠŸï¼ˆä½¿ç”¨ Supabase ç¼“å­˜æ•°æ®ï¼‰',
                    'cached': True
                }
            except Exception as cache_error:
                print(f"[WARN] è¯»å– Supabase ç¼“å­˜æ•°æ®å¤±è´¥: {cache_error}ï¼Œå°†é‡æ–°ç”Ÿæˆ")

        # print(f"[INFO] æå–åˆ°è§†é¢‘ ID: {video_id}")

        # è·å–å®Œæ•´å­—å¹•ä¸è§†é¢‘è¯¦æƒ…ï¼ˆæ³¨æ„ä¼ å…¥çš„æ˜¯å®Œæ•´ URLï¼‰
        result = get_full_transcript(url, language='en')
        if not result or result == (None, None):
            raise HTTPException(status_code=500, detail='æ— æ³•è·å–è§†é¢‘å­—å¹•')

        transcript, details = result
        
        # å†æ¬¡æ£€æŸ¥è§£åŒ…åçš„å€¼
        if not transcript or not details:
            raise HTTPException(status_code=500, detail='æ— æ³•è·å–è§†é¢‘å­—å¹•æˆ–è¯¦æƒ…')

        # ä½¿ç”¨ LangChain LLM æœåŠ¡å¤„ç†å’Œç»“æ„åŒ–å­—å¹•
        try:
            print(f"[INFO] å¼€å§‹ä½¿ç”¨ LangChain å¤„ç†å­—å¹•...")
            llm_service = get_llm_service()
            video_analysis = llm_service.analyze_video_transcript(transcript, details, video_id)
            video_data_json = video_analysis.model_dump()
            print(f"[INFO] LangChain ç”Ÿæˆç»“æ„åŒ–æ•°æ®ï¼Œlanguage: {language}")
            
            # è·å–ç« èŠ‚ç¼©ç•¥å›¾å’Œè§†é¢‘æ ‡é¢˜
            video_title = ''
            try:
                print(f"[INFO] æ­£åœ¨è·å–ç« èŠ‚ç¼©ç•¥å›¾...")
                video_title, chapters = extract_youtube_chapters(video_id)
                
                # ä½¿ç”¨æ­£ç¡®çš„è§†é¢‘æ ‡é¢˜æ›´æ–° JSON
                if video_title:
                    video_data_json['videoInfo']['title'] = video_title
                    print(f"[SUCCESS] æ›´æ–°è§†é¢‘æ ‡é¢˜: {video_title}")
                
                if chapters:
                    # å°†ç« èŠ‚ç¼©ç•¥å›¾æ·»åŠ åˆ° JSON æ•°æ®ä¸­
                    video_data_json['chapters'] = chapters
                    print(f"[SUCCESS] è·å–åˆ° {len(chapters)} ä¸ªç« èŠ‚ç¼©ç•¥å›¾")
                else:
                    video_data_json['chapters'] = []
                    print(f"[INFO] è¯¥è§†é¢‘æ²¡æœ‰ç« èŠ‚ä¿¡æ¯")
            except Exception as chapter_error:
                print(f"[WARN] è·å–ç« èŠ‚ç¼©ç•¥å›¾å¤±è´¥: {chapter_error}")
                video_data_json['chapters'] = []
                video_title = details.get('title', '') if details else ''
            
            # ä½¿ç”¨ display_full_transcript è·å–æ ¼å¼åŒ–çš„å­—å¹•
            from get_full_transcript_ytdlp import display_full_transcript
            
            output_lines = display_full_transcript(transcript, details=details)
            
            # ç»„è£…å®Œæ•´æ–‡æœ¬ï¼ˆæ ‡é¢˜ + åˆ†éš”çº¿ + å†…å®¹ï¼‰
            video_title = video_data_json.get('videoInfo', {}).get('title', f'Video {video_id}')
            transcript_text = f"{video_title}\n{'=' * 70}\n\n" + '\n'.join(output_lines)
            
            # ä¿å­˜åˆ° Supabase
            save_video_to_supabase(
                video_id=video_id,
                video_data=video_data_json,
                transcript=transcript_text,
                chapters=video_data_json.get('chapters', [])
            )
            
            
            # å¦‚æœç›®æ ‡è¯­è¨€ä¸æ˜¯è‹±æ–‡ï¼Œç¿»è¯‘æ•°æ®åè¿”å›
            response_data = video_data_json
            if language and language != 'en':
                print(f"[INFO] æ­£åœ¨å°†ç”Ÿæˆçš„æ•°æ®ç¿»è¯‘ä¸º {language}...")
                response_data = translate_cached_data(video_data_json, language)
            
            return {
                'success': True,
                'videoId': video_id,
                'title': response_data.get('videoInfo', {}).get('title', video_title),
                'transcriptLength': len(transcript),
                'dataFile': f"video-data-{video_id}.json",
                'chapters': response_data.get('chapters', []),
                'sections': response_data.get('sections', []),
                'videoInfo': response_data.get('videoInfo', {}),
                'message': 'è§†é¢‘å¤„ç†æˆåŠŸ',
                'cached': False
            }
        except Exception as llm_error:
            print(f"[WARN] LLM å¤„ç†å¤±è´¥: {llm_error}, è¿”å›åŸºæœ¬ä¿¡æ¯")
            # LLM å¤±è´¥æ—¶ä»è¿”å›æˆåŠŸï¼Œä½†ä¸åŒ…å«ç»“æ„åŒ–æ•°æ®
            return {
                'success': True,
                'videoId': video_id,
                'title': details.get('title', '') if details else '',
                'transcriptLength': len(transcript) if transcript else 0,
                'message': 'è§†é¢‘å¤„ç†æˆåŠŸï¼ˆæœªä½¿ç”¨ LLM ç»“æ„åŒ–ï¼‰',
                'warning': str(llm_error)
            }

    except Exception as e:
        import traceback
        print(f"[ERROR] /api/process-video å¤„ç†å¤±è´¥: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f'è§†é¢‘å¤„ç†å¤±è´¥: {str(e)}')


@app.post('/api/process-video/stream')
async def process_video_stream(request_data: ProcessVideoRequest):
    """
    æµå¼å¤„ç† YouTube è§†é¢‘ URL - ç›´æ¥è¾“å‡º LLM ç”Ÿæˆçš„å†…å®¹
    
    è¿”å› Server-Sent Events (SSE) æ ¼å¼ï¼š
    - ç›´æ¥å‘é€ LLM ç”Ÿæˆçš„æ–‡æœ¬ç‰‡æ®µï¼ˆæ— å‰ç¼€ï¼‰
    - data: [DONE] å®Œæ•´JSONç»“æœ
    - data: [CACHED] ç¼“å­˜çš„å®Œæ•´JSONç»“æœ  
    - data: [ERROR] é”™è¯¯æ¶ˆæ¯
    """
    import time
    url = request_data.url
    language = request_data.language
    user_id = request_data.user_id  # å¯é€‰ï¼šç”¨äºè®°å½•ä½¿ç”¨æ¬¡æ•°
    
    print(f"[STREAM] ğŸ“¥ æ”¶åˆ°è¯·æ±‚: url={url}, language={language}, user_id={user_id[:8] + '...' if user_id else 'anonymous'}", flush=True)

    async def generate():
        try:
            sys.path.append(str(BASE_DIR))
            from get_full_transcript_ytdlp import get_full_transcript, display_full_transcript
            from youtube_client import YouTubeClient

            # æå–è§†é¢‘ ID
            video_id = YouTubeClient.extract_video_id(url)
            print(f"[STREAM] ğŸ¬ è§†é¢‘ID: {video_id}", flush=True)
            if not video_id:
                print(f"[STREAM] âŒ æ— æ³•æå–è§†é¢‘ID", flush=True)
                yield 'data: [ERROR] æ— æ³•ä»URLæå–è§†é¢‘ID\n\n'
                return

            # æ£€æŸ¥ç¼“å­˜
            print(f"[STREAM] ğŸ” æ£€æŸ¥ç¼“å­˜...", flush=True)
            cached_record = get_cached_video_from_supabase(video_id)
            if cached_record and cached_record.get('video_data'):
                print(f"[STREAM] âœ… å‘½ä¸­ç¼“å­˜ï¼Œç›´æ¥è¿”å›", flush=True)
                cached_data = cached_record['video_data']
                if language and language != 'en':
                    cached_data = translate_cached_data(cached_data, language)
                yield f'data: [CACHED] {json.dumps(cached_data, ensure_ascii=False)}\n\n'
                return

            # è·å–å­—å¹•
            print(f"[STREAM] ğŸ“ å¼€å§‹è·å–å­—å¹•...", flush=True)
            start_time = time.time()
            result = get_full_transcript(url, language='en')
            print(f"[STREAM] ğŸ“ å­—å¹•è·å–å®Œæˆï¼Œè€—æ—¶: {time.time() - start_time:.2f}s", flush=True)
            
            if not result or result == (None, None):
                print(f"[STREAM] âŒ æ— æ³•è·å–å­—å¹•", flush=True)
                yield 'data: [ERROR] æ— æ³•è·å–è§†é¢‘å­—å¹•\n\n'
                return

            transcript, details = result
            if not transcript or not details:
                print(f"[STREAM] âŒ å­—å¹•æˆ–è¯¦æƒ…ä¸ºç©º", flush=True)
                yield 'data: [ERROR] å­—å¹•æˆ–è¯¦æƒ…ä¸ºç©º\n\n'
                return
            
            print(f"[STREAM] ğŸ“ å­—å¹•æ¡æ•°: {len(transcript)}", flush=True)

            # æµå¼ LLM åˆ†æ - ä½¿ç”¨åˆ†æ®µäº‹ä»¶æµ
            print(f"[STREAM] ğŸ¤– å¼€å§‹ LLM æµå¼åˆ†æ...", flush=True)
            llm_start = time.time()
            llm_service = get_llm_service()
            full_response = ""
            chunk_count = 0
            
            # å¢é‡è§£æçŠ¶æ€
            video_info_sent = False
            sent_section_ids = set()
            
            def send_event(event_type: str, data: dict):
                """å‘é€ç»“æ„åŒ–äº‹ä»¶"""
                event = {"type": event_type, "data": data}
                return f'data: {json.dumps(event, ensure_ascii=False)}\n\n'
            
            def try_parse_video_info(content: str):
                """å°è¯•ä»ç´¯ç§¯å†…å®¹ä¸­è§£æ videoInfo"""
                import re
                # æ¸…ç† markdown
                text = re.sub(r'^```json?\s*', '', content.strip())
                
                # æŸ¥æ‰¾ videoInfo å¯¹è±¡
                match = re.search(r'"videoInfo"\s*:\s*(\{)', text)
                if not match:
                    return None
                
                start = match.end() - 1  # { çš„ä½ç½®
                depth = 0
                for i in range(start, len(text)):
                    if text[i] == '{':
                        depth += 1
                    elif text[i] == '}':
                        depth -= 1
                        if depth == 0:
                            try:
                                return json.loads(text[start:i+1])
                            except:
                                return None
                return None
            
            def try_parse_sections(content: str, seen_ids: set):
                """å°è¯•ä»ç´¯ç§¯å†…å®¹ä¸­è§£ææ–°çš„ sections"""
                import re
                text = re.sub(r'^```json?\s*', '', content.strip())
                
                # æŸ¥æ‰¾ sections æ•°ç»„
                match = re.search(r'"sections"\s*:\s*\[', text)
                if not match:
                    return []
                
                start = match.end()
                new_sections = []
                
                # æŸ¥æ‰¾æ¯ä¸ª section å¯¹è±¡
                i = start
                while i < len(text):
                    # è·³è¿‡ç©ºç™½å’Œé€—å·
                    while i < len(text) and text[i] in ' \t\n\r,':
                        i += 1
                    if i >= len(text) or text[i] == ']':
                        break
                    if text[i] != '{':
                        i += 1
                        continue
                    
                    # æ‰¾åˆ°å¯¹è±¡å¼€å§‹ï¼Œå¯»æ‰¾é—­åˆ
                    obj_start = i
                    depth = 0
                    for j in range(i, len(text)):
                        if text[j] == '{':
                            depth += 1
                        elif text[j] == '}':
                            depth -= 1
                            if depth == 0:
                                try:
                                    section = json.loads(text[obj_start:j+1])
                                    if section.get('id') and section['id'] not in seen_ids:
                                        new_sections.append(section)
                                        seen_ids.add(section['id'])
                                except:
                                    pass
                                i = j + 1
                                break
                    else:
                        break  # å¯¹è±¡æœªé—­åˆï¼Œç­‰å¾…æ›´å¤šæ•°æ®
                
                return new_sections
            
            async for chunk in llm_service.analyze_video_transcript_stream(transcript, details, video_id):
                if chunk == "\n[STREAM_END]":
                    continue
                full_response += chunk
                chunk_count += 1
                
                # å°è¯•å¢é‡è§£æå¹¶å‘é€äº‹ä»¶
                if not video_info_sent:
                    video_info = try_parse_video_info(full_response)
                    if video_info:
                        print(f"[STREAM] ğŸ“¤ å‘é€ video_info äº‹ä»¶", flush=True)
                        yield send_event("video_info", video_info)
                        video_info_sent = True
                
                # å°è¯•è§£ææ–°çš„ sections
                new_sections = try_parse_sections(full_response, sent_section_ids)
                for section in new_sections:
                    print(f"[STREAM] ğŸ“¤ å‘é€ section äº‹ä»¶: {section.get('id')}", flush=True)
                    yield send_event("section", section)
                
                if chunk_count % 20 == 0:
                    print(f"[STREAM] ğŸ”„ chunk#{chunk_count}, é•¿åº¦:{len(full_response)}", flush=True)
            
            print(f"[STREAM] ğŸ¤– LLM æµå¼è¾“å‡ºå®Œæˆï¼Œè€—æ—¶: {time.time() - llm_start:.2f}s, æ€»chunks: {chunk_count}", flush=True)

            # === è§£æå®Œæ•´ç»“æœ ===
            print(f"[STREAM] ğŸ“Š è§£æå®Œæ•´ JSON...", flush=True)
            try:
                video_analysis = llm_service.parse_analysis_result(full_response)
                video_data_json = video_analysis.model_dump()
                print(f"[STREAM] âœ… JSON è§£ææˆåŠŸï¼Œsections: {len(video_data_json.get('sections', []))}", flush=True)
            except Exception as parse_error:
                print(f"[STREAM] âš ï¸ JSON è§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å“åº”: {parse_error}", flush=True)
                try:
                    import re
                    text = re.sub(r'^```json?\s*', '', full_response.strip())
                    text = re.sub(r'\s*```$', '', text)
                    video_data_json = json.loads(text)
                except:
                    video_data_json = {"videoInfo": {"title": details.get('title', ''), "videoId": video_id}, "sections": []}

            # è·å–ç« èŠ‚
            try:
                video_title, chapters = extract_youtube_chapters(video_id)
                if video_title:
                    video_data_json['videoInfo']['title'] = video_title
                video_data_json['chapters'] = chapters or []
            except:
                video_data_json['chapters'] = []

            # å‘é€å®Œæ•´çš„ JSON ç»™å‰ç«¯ï¼ˆä¸ [CACHED] æ ¼å¼ä¿æŒä¸€è‡´ï¼‰
            yield f'data: [DONE] {json.dumps(video_data_json, ensure_ascii=False)}\n\n'
            print(f"[STREAM] ğŸ“¤ å·²å‘é€ [DONE] å®Œæ•´ JSON", flush=True)

            # ä¿å­˜åˆ° Supabaseï¼ˆåå°å¤„ç†ï¼Œä¸é˜»å¡å‰ç«¯ï¼‰
            print(f"[STREAM] ğŸ’¾ ä¿å­˜åˆ° Supabase...", flush=True)
            output_lines = display_full_transcript(transcript, details=details)
            video_title = video_data_json.get('videoInfo', {}).get('title', f'Video {video_id}')
            transcript_text = f"{video_title}\n{'=' * 70}\n\n" + '\n'.join(output_lines)
            
            save_video_to_supabase(
                video_id=video_id,
                video_data=video_data_json,
                transcript=transcript_text,
                chapters=video_data_json.get('chapters', [])
            )
            
            # è®°å½•ç”¨æˆ·ä½¿ç”¨ï¼ˆå¦‚æœæœ‰ user_idï¼‰
            if user_id:
                record_user_usage(
                    user_id=user_id,
                    video_id=video_id,
                    video_title=video_title,
                    action_type="analysis"
                )
            
            print(f"[STREAM] âœ… å¤„ç†å®Œæˆ", flush=True)

        except Exception as e:
            import traceback
            print(f"[STREAM] âŒ å¼‚å¸¸: {e}", flush=True)
            traceback.print_exc()
            yield f'data: [ERROR] {str(e)}\n\n'

    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@app.post("/api/translate-themes")
async def translate_themes(request: Request):
    """ç¿»è¯‘ themes æ•°æ®ä¸ºç›®æ ‡è¯­è¨€"""
    try:
        data = await request.json()
        themes = data.get('themes', [])
        target_language = data.get('language', 'en')
        
        if target_language == 'en' or not themes:
            return {"success": True, "themes": themes}
        
        # ä½¿ç”¨ LLM ç¿»è¯‘ themes
        llm_service = get_llm_service()
        
        # æ„å»ºç¿»è¯‘è¯·æ±‚
        themes_text = json.dumps(themes, ensure_ascii=False)
        
        language_names = {
            'zh': 'Chinese',
            'ja': 'Japanese', 
            'ko': 'Korean',
            'es': 'Spanish',
            'fr': 'French',
        }
        target_lang_name = language_names.get(target_language, target_language)
        
        prompt = f"""Translate the following JSON themes data to {target_lang_name}. 
Keep the JSON structure exactly the same, only translate the text content (title, description, content fields).
Do NOT translate field names like "id", "title", "content", "timestampStart", "color".
Return ONLY the translated JSON array, no explanation.

{themes_text}"""
        
        translated_text = llm_service.llm.invoke(prompt).content.strip()
        
        # æ¸…ç†å¯èƒ½çš„ markdown ä»£ç å—
        if translated_text.startswith('```'):
            translated_text = translated_text.split('\n', 1)[1] if '\n' in translated_text else translated_text[3:]
        if translated_text.endswith('```'):
            translated_text = translated_text[:-3]
        translated_text = translated_text.strip()
        
        translated_themes = json.loads(translated_text)
        print(f"[SUCCESS] ç¿»è¯‘äº† {len(translated_themes)} ä¸ª themes åˆ° {target_language}")
        
        return {"success": True, "themes": translated_themes}
    except Exception as e:
        print(f"[ERROR] ç¿»è¯‘ themes å¤±è´¥: {e}")
        return {"success": False, "error": str(e), "themes": data.get('themes', [])}


def translate_cached_data(cached_data: dict, target_language_code: str) -> dict:
    """
    ä½¿ç”¨ LangChain ç¿»è¯‘ç¼“å­˜æ•°æ®
    """
    if target_language_code == 'en':
        return cached_data
    
    try:
        llm_service = get_llm_service()
        return llm_service.translate_video_data(cached_data, target_language_code)
    except Exception as e:
        print(f"[WARN] ç¿»è¯‘å¤±è´¥: {e}ï¼Œè¿”å›åŸå§‹æ•°æ®")
        return cached_data


# æä¾›é™æ€æ–‡ä»¶
@app.get("/")
async def root():
    """è¿”å›é¦–é¡µ"""
    index_path = STATIC_DIR / "index.html"
    return FileResponse(index_path)


# æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½•
app.mount("/css", StaticFiles(directory=str(STATIC_DIR / "css")), name="css")
app.mount("/js", StaticFiles(directory=str(STATIC_DIR / "js")), name="js")
app.mount("/data", StaticFiles(directory=str(STATIC_DIR / "data")), name="data")


if __name__ == "__main__":
    import uvicorn
    import os 

    # SSL è¯ä¹¦è·¯å¾„
    ssl_keyfile = "/home/ubuntu/PageOn_video_web/ssl/server.key"
    ssl_certfile = "/home/ubuntu/PageOn_video_web/ssl/server.crt"

    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ SSL è¯ä¹¦
    use_https = os.path.exists(ssl_keyfile) and os.path.exists(ssl_certfile)


    if use_https:
        print("ğŸ”’ Server is running on https://localhost:5500 (HTTPS)")
        print("ğŸ“Š API endpoint: https://localhost:5500/api")
        print("ğŸ“š API docs: https://localhost:5500/docs")
        uvicorn.run(
            app, 
            host="0.0.0.0", 
            port=5500,
            ssl_keyfile=ssl_keyfile,
            ssl_certfile=ssl_certfile
        )
    else:
        print("ğŸš€ Server is running on http://localhost:5500 (HTTP)")
        print("ğŸ“Š API endpoint: http://localhost:5500/api")
        print("ğŸ“š API docs: http://localhost:5500/docs")
        print("âš ï¸  No SSL certificates found. To enable HTTPS, create:")
        print(f"    - {ssl_keyfile}")
        print(f"    - {ssl_certfile}")
        uvicorn.run(app, host="0.0.0.0", port=5500)
